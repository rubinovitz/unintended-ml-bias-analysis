{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Toxicity Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a model to detect toxicity in online comments. It uses a CNN architecture for text classification trained on the [Wikipedia Talk Labels: Toxicity dataset](https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973) and pre-trained GloVe embeddings which can be found at:\n",
    "http://nlp.stanford.edu/data/glove.6B.zip\n",
    "(source page: http://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "This model is a modification of [example code](https://github.com/fchollet/keras/blob/master/examples/pretrained_word_embeddings.py) found in the [Keras Github repository](https://github.com/fchollet/keras) and released under an [MIT license](https://github.com/fchollet/keras/blob/master/LICENSE). For further details of this license, find it [online](https://github.com/fchollet/keras/blob/master/LICENSE) or in this repository in the file KERAS_LICENSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "(TODO: nthain) - Move to README\n",
    "\n",
    "Prior to running the notebook, you must:\n",
    "\n",
    "* Download the [Wikipedia Talk Labels: Toxicity dataset](https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973)\n",
    "* Download pre-trained [GloVe embeddings](http://nlp.stanford.edu/data/glove.6B.zip)\n",
    "* (optional) To skip the training step, you will need to download a model and tokenizer file. We are looking into the appropriate means for distributing these (sometimes large) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO from model_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn rate: 5e-05\n",
      "seq len: 250\n",
      "num words: 5000\n",
      "epochs: 8\n",
      "dropout: 0.3\n",
      "\n",
      "embedding dim: 100\n",
      "batch size: 128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from model_tool import ToxModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPLITS = ['train', 'dev', 'test']\n",
    "\n",
    "wiki = {}\n",
    "debias = {}\n",
    "random = {}\n",
    "for split in SPLITS:\n",
    "    wiki[split] = '../data/wiki_%s.csv' % split\n",
    "    debias[split] = '../data/wiki_debias_%s.csv' % split\n",
    "    random[split] = '../data/wiki_debias_random_%s.csv' % split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HUNT MODEL VARIANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import model_tool\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_colwidth', 135)\n",
    "\n",
    "def hack_score(model, texts, maxlen=1000):\n",
    "    sequences = model.tokenizer.texts_to_sequences(texts)\n",
    "    data = pad_sequences(sequences, maxlen=maxlen)\n",
    "    return model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hack attempt 1 10-03\n",
    "\n",
    "trained multiple 5 copies of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training spooky_orig_v0 2017-10-04 00:21:56.333810\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/3\n",
      "95692/95692 [==============================] - 585s - loss: 0.1460 - acc: 0.9479 - val_loss: 0.1030 - val_acc: 0.9617\n",
      "Epoch 2/3\n",
      "95692/95692 [==============================] - 585s - loss: 0.1003 - acc: 0.9640 - val_loss: 0.1362 - val_acc: 0.9546\n",
      "Epoch 3/3\n",
      "95692/95692 [==============================] - 585s - loss: 0.0914 - acc: 0.9678 - val_loss: 0.1176 - val_acc: 0.9645\n",
      "<keras.callbacks.History object at 0x7fb4cd4c7610>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_debias_v0 2017-10-04 00:51:37.893455\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 607s - loss: 0.1450 - acc: 0.9489 - val_loss: 0.1290 - val_acc: 0.9571\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 637s - loss: 0.1006 - acc: 0.9641 - val_loss: 0.1064 - val_acc: 0.9643\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 727s - loss: 0.0902 - acc: 0.9682 - val_loss: 0.1106 - val_acc: 0.9642\n",
      "<keras.callbacks.History object at 0x7fb4b97d6450>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_random_v0 2017-10-04 01:24:55.685358\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 725s - loss: 0.1433 - acc: 0.9489 - val_loss: 0.1140 - val_acc: 0.9571\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 677s - loss: 0.0980 - acc: 0.9649 - val_loss: 0.1003 - val_acc: 0.9631\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 671s - loss: 0.0875 - acc: 0.9680 - val_loss: 0.1272 - val_acc: 0.9646\n",
      "<keras.callbacks.History object at 0x7fb32cfba810>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_orig_v1 2017-10-04 01:59:58.437484\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/3\n",
      "95692/95692 [==============================] - 680s - loss: 0.1464 - acc: 0.9471 - val_loss: 0.1109 - val_acc: 0.9589\n",
      "Epoch 2/3\n",
      "95692/95692 [==============================] - 668s - loss: 0.1003 - acc: 0.9637 - val_loss: 0.1096 - val_acc: 0.9644\n",
      "Epoch 3/3\n",
      "95692/95692 [==============================] - 639s - loss: 0.0892 - acc: 0.9676 - val_loss: 0.1057 - val_acc: 0.9636\n",
      "<keras.callbacks.History object at 0x7fb310a93610>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_debias_v1 2017-10-04 02:33:36.343433\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 721s - loss: 0.1447 - acc: 0.9486 - val_loss: 0.1044 - val_acc: 0.9622\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 722s - loss: 0.1002 - acc: 0.9645 - val_loss: 0.1121 - val_acc: 0.9620\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 728s - loss: 0.0888 - acc: 0.9683 - val_loss: 0.1065 - val_acc: 0.9623\n",
      "<keras.callbacks.History object at 0x7fb2e91515d0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_random_v1 2017-10-04 03:10:16.787705\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 682s - loss: 0.1417 - acc: 0.9500 - val_loss: 0.0995 - val_acc: 0.9636\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 684s - loss: 0.0986 - acc: 0.9645 - val_loss: 0.1147 - val_acc: 0.9622\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 679s - loss: 0.0889 - acc: 0.9676 - val_loss: 0.1209 - val_acc: 0.9635\n",
      "<keras.callbacks.History object at 0x7fb2e2d54910>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_orig_v2 2017-10-04 03:44:53.956422\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/3\n",
      "95692/95692 [==============================] - 701s - loss: 0.1471 - acc: 0.9479 - val_loss: 0.1014 - val_acc: 0.9624\n",
      "Epoch 2/3\n",
      "95692/95692 [==============================] - 696s - loss: 0.1010 - acc: 0.9636 - val_loss: 0.1034 - val_acc: 0.9639\n",
      "Epoch 3/3\n",
      "95692/95692 [==============================] - 698s - loss: 0.0883 - acc: 0.9680 - val_loss: 0.1136 - val_acc: 0.9595\n",
      "<keras.callbacks.History object at 0x7fb2b711e5d0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_debias_v2 2017-10-04 04:20:20.936277\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 731s - loss: 0.1439 - acc: 0.9498 - val_loss: 0.1157 - val_acc: 0.9621\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 730s - loss: 0.1012 - acc: 0.9648 - val_loss: 0.1004 - val_acc: 0.9643\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 737s - loss: 0.0904 - acc: 0.9679 - val_loss: 0.1117 - val_acc: 0.9609\n",
      "<keras.callbacks.History object at 0x7fb2852904d0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_random_v2 2017-10-04 04:57:32.148778\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 925s - loss: 0.1438 - acc: 0.9499 - val_loss: 0.1109 - val_acc: 0.9624\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 608s - loss: 0.0981 - acc: 0.9651 - val_loss: 0.1044 - val_acc: 0.9625\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 607s - loss: 0.0867 - acc: 0.9689 - val_loss: 0.1057 - val_acc: 0.9622\n",
      "<keras.callbacks.History object at 0x7fb264735dd0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_orig_v3 2017-10-04 05:33:44.149034\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/3\n",
      "95692/95692 [==============================] - 589s - loss: 0.1453 - acc: 0.9488 - val_loss: 0.1020 - val_acc: 0.9624\n",
      "Epoch 2/3\n",
      "95692/95692 [==============================] - 580s - loss: 0.1015 - acc: 0.9637 - val_loss: 0.1036 - val_acc: 0.9641\n",
      "Epoch 3/3\n",
      "95692/95692 [==============================] - 601s - loss: 0.0897 - acc: 0.9680 - val_loss: 0.0987 - val_acc: 0.9649\n",
      "<keras.callbacks.History object at 0x7fb23cf5a5d0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_debias_v3 2017-10-04 06:03:43.984520\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 673s - loss: 0.1449 - acc: 0.9494 - val_loss: 0.1049 - val_acc: 0.9633\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 725s - loss: 0.0987 - acc: 0.9646 - val_loss: 0.1048 - val_acc: 0.9645\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 707s - loss: 0.0865 - acc: 0.9682 - val_loss: 0.1046 - val_acc: 0.9655\n",
      "<keras.callbacks.History object at 0x7fb2245bfd90>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_random_v3 2017-10-04 06:39:20.943443\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 748s - loss: 0.1427 - acc: 0.9484 - val_loss: 0.1023 - val_acc: 0.9625\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 886s - loss: 0.0988 - acc: 0.9648 - val_loss: 0.1011 - val_acc: 0.9641\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 939s - loss: 0.0894 - acc: 0.9682 - val_loss: 0.1165 - val_acc: 0.9634\n",
      "<keras.callbacks.History object at 0x7fb217178210>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_orig_v4 2017-10-04 07:22:49.310211\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/3\n",
      "95692/95692 [==============================] - 796s - loss: 0.1477 - acc: 0.9485 - val_loss: 0.1026 - val_acc: 0.9617\n",
      "Epoch 2/3\n",
      "95692/95692 [==============================] - 848s - loss: 0.1008 - acc: 0.9635 - val_loss: 0.1113 - val_acc: 0.9614\n",
      "Epoch 3/3\n",
      "95692/95692 [==============================] - 704s - loss: 0.0910 - acc: 0.9674 - val_loss: 0.1002 - val_acc: 0.9648\n",
      "<keras.callbacks.History object at 0x7fb1f6e5ee90>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_debias_v4 2017-10-04 08:02:29.707528\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 1119s - loss: 0.1408 - acc: 0.9511 - val_loss: 0.1166 - val_acc: 0.9607\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 1278s - loss: 0.1001 - acc: 0.9646 - val_loss: 0.0991 - val_acc: 0.9642\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 1126s - loss: 0.0879 - acc: 0.9678 - val_loss: 0.1293 - val_acc: 0.9637\n",
      "<keras.callbacks.History object at 0x7fb1bd3242d0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_random_v4 2017-10-04 09:01:47.002383\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 1173s - loss: 0.1430 - acc: 0.9488 - val_loss: 0.1034 - val_acc: 0.9618\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 1068s - loss: 0.0975 - acc: 0.9651 - val_loss: 0.1113 - val_acc: 0.9638\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 1248s - loss: 0.0861 - acc: 0.9688 - val_loss: 0.1035 - val_acc: 0.9643\n",
      "<keras.callbacks.History object at 0x7fb1a4d98710>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_orig_v5 2017-10-04 10:00:32.854873\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/3\n",
      "95692/95692 [==============================] - 1135s - loss: 0.1450 - acc: 0.9487 - val_loss: 0.1085 - val_acc: 0.9596\n",
      "Epoch 2/3\n",
      "95692/95692 [==============================] - 1043s - loss: 0.1012 - acc: 0.9637 - val_loss: 0.1002 - val_acc: 0.9643\n",
      "Epoch 3/3\n",
      "95692/95692 [==============================] - 1153s - loss: 0.0906 - acc: 0.9679 - val_loss: 0.1147 - val_acc: 0.9636\n",
      "<keras.callbacks.History object at 0x7fb196d6e4d0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "training spooky_debias_v5 2017-10-04 10:57:25.938144\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "79104/99157 [======================>.......] - ETA: 123s - loss: 0.1550 - acc: 0.9460"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5bf516b16658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"\\nfrom __future__ import absolute_import\\nfrom __future__ import division\\nfrom __future__ import print_function\\n\\nimport datetime\\n\\n\\nwiki['name'] = 'orig'\\ndebias['name'] = 'debias'\\nrandom['name'] = 'random'\\n\\ntest_results = {}\\nspooky_models = []\\n\\nfor i in xrange(6):\\n    for m in [wiki, debias, random]:\\n        name = 'spooky_{}_v{}'.format(m['name'], i)\\n        print('training', name, datetime.datetime.now())\\n        model = ToxModel()\\n        model.train(m['train'], m['dev'], text_column='comment', label_column='is_toxic', model_name=name)\\n        spooky_models.append((name, model))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/src/model_tool.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data_path, validation_data_path, text_column, label_column, model_name)\u001b[0m\n\u001b[1;32m    131\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m           validation_data=(valid_data, valid_labels)))\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model trained!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "\n",
    "wiki['name'] = 'orig'\n",
    "debias['name'] = 'debias'\n",
    "random['name'] = 'random'\n",
    "\n",
    "test_results = {}\n",
    "spooky_models = []\n",
    "\n",
    "for i in xrange(6):\n",
    "    for m in [wiki, debias, random]:\n",
    "        name = 'spooky_{}_v{}'.format(m['name'], i)\n",
    "        print('training', name, datetime.datetime.now())\n",
    "        model = ToxModel()\n",
    "        model.train(m['train'], m['dev'], text_column='comment', label_column='is_toxic', model_name=name)\n",
    "        spooky_models.append((name, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spooky_orig_v0', <model_tool.ToxModel instance at 0x7fb4f6ef2e18>),\n",
       " ('spooky_debias_v0', <model_tool.ToxModel instance at 0x7fb4cf07c878>),\n",
       " ('spooky_random_v0', <model_tool.ToxModel instance at 0x7fb4b93243f8>),\n",
       " ('spooky_orig_v1', <model_tool.ToxModel instance at 0x7fb4cbb9fdd0>),\n",
       " ('spooky_debias_v1', <model_tool.ToxModel instance at 0x7fb310bbf368>),\n",
       " ('spooky_random_v1', <model_tool.ToxModel instance at 0x7fb2e8f48e60>),\n",
       " ('spooky_orig_v2', <model_tool.ToxModel instance at 0x7fb2e32b1128>),\n",
       " ('spooky_debias_v2', <model_tool.ToxModel instance at 0x7fb2b4d6b3f8>),\n",
       " ('spooky_random_v2', <model_tool.ToxModel instance at 0x7fb27cb1e560>),\n",
       " ('spooky_orig_v3', <model_tool.ToxModel instance at 0x7fb2648eb560>),\n",
       " ('spooky_debias_v3', <model_tool.ToxModel instance at 0x7fb23cd54290>),\n",
       " ('spooky_random_v3', <model_tool.ToxModel instance at 0x7fb22496bc20>),\n",
       " ('spooky_orig_v4', <model_tool.ToxModel instance at 0x7fb216ce3290>),\n",
       " ('spooky_debias_v4', <model_tool.ToxModel instance at 0x7fb1f4a1d758>),\n",
       " ('spooky_random_v4', <model_tool.ToxModel instance at 0x7fb1bceaf6c8>)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spooky_models2 = spooky_models[:-1]\n",
    "spooky_models2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring 0 spooky_orig_v0 2017-10-04 11:12:12.684036\n",
      "scoring 0 spooky_debias_v0 2017-10-04 11:13:42.611486\n",
      "scoring 0 spooky_random_v0 2017-10-04 11:15:38.811669\n",
      "scoring 0 spooky_orig_v1 2017-10-04 11:17:07.660048\n",
      "scoring 0 spooky_debias_v1 2017-10-04 11:18:52.076721\n",
      "scoring 0 spooky_random_v1 2017-10-04 11:20:48.096026\n",
      "scoring 0 spooky_orig_v2 2017-10-04 11:22:19.801965\n",
      "scoring 0 spooky_debias_v2 2017-10-04 11:23:49.042078\n",
      "scoring 0 spooky_random_v2 2017-10-04 11:27:02.968241\n",
      "scoring 0 spooky_orig_v3 2017-10-04 11:28:33.812361\n",
      "scoring 0 spooky_debias_v3 2017-10-04 11:30:04.218309\n",
      "scoring 0 spooky_random_v3 2017-10-04 11:32:04.785935\n",
      "scoring 0 spooky_orig_v4 2017-10-04 11:33:34.530306\n",
      "scoring 0 spooky_debias_v4 2017-10-04 11:35:04.777843\n",
      "scoring 0 spooky_random_v4 2017-10-04 11:38:03.601047\n",
      "scoring 1 spooky_orig_v0 2017-10-04 11:42:31.448177\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-367cc9d709b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"\\nimport pandas as pd\\n\\ntest_sets = [pd.read_csv(path) for path in [wiki['test'], debias['test'], random['test']]]\\n\\nfor i, test_set in enumerate(test_sets):\\n    for (name, model) in spooky_models2:\\n        print('scoring', i, name, datetime.datetime.now())\\n        test_results[name] = hack_score(model, test_set['comment'])\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b5de3e66facf>\u001b[0m in \u001b[0;36mhack_score\u001b[0;34m(model, texts)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/src/model_tool.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprep_data_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1713\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_sets = [pd.read_csv(path) for path in [wiki['test'], debias['test'], random['test']]]\n",
    "\n",
    "for i, test_set in enumerate(test_sets):\n",
    "    for (name, model) in spooky_models2:\n",
    "        print('scoring', i, name, datetime.datetime.now())\n",
    "        test_results[name] = hack_score(model, test_set['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_results = [test_results['spooky_orig_v0'], test_results['spooky_orig_v1'], test_results['spooky_orig_v2'],\n",
    "                test_results['spooky_orig_v3'], test_results['spooky_orig_v4']] \n",
    "debias_results = [test_results['spooky_debias_v0'], test_results['spooky_debias_v1'], test_results['spooky_debias_v2'],\n",
    "                  test_results['spooky_debias_v3'], test_results['spooky_debias_v4']] \n",
    "random_results = [test_results['spooky_random_v0'], test_results['spooky_random_v1'], test_results['spooky_random_v2'],\n",
    "                  test_results['spooky_random_v3'], test_results['spooky_random_v4']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting score histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig scores\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACBBJREFUeJzt3V+MVGcdxvHvIwQaa4JUuGiAZSAhrdur1gk1mvjfdCna\n9U9iIJoUxSJVvPFGDDfGG7kzMZI0xBD0BopcsYJpqi3hprRdklqghHa7pYGNkVKUxGio1J8Xe0gP\nU3Y9s/ObObPj80k2nHnPv19OePa87zszZxURmFnnPlB3AWaDwmEyS+IwmSVxmMySOExmSRwmsyQO\nk1kSh8ksicNklmRh3QUALFu2LBqNRt1lmL3PqVOnrkTE8irb9kWYGo0G4+PjdZdh9j6S3qy6rbt5\nZkkcJrMktYZJ0pcl7b127VqdZZilqHXMFBFjwFiz2Xxstu0aO4/O+RwXdm+c875m7XA3zyyJw2SW\nxGEyS+IwmSVxmMySOExmSfw+k1mSWsMUEWMRsW3JkiV1lmGWwt08syQOk1kSh8ksicNklsRhMkvi\nMJklcZjMkjhMZkm6EiZJd0oal/SlbhzfrB9VCpOkfZIuSzrT0j4i6bykCUk7S6t+DBzKLNSs31W9\nM+0HRsoNkhYAe4ANwDCwWdKwpC8CrwCXE+s063uVngERESckNVqa1wMTETEJIOkgMAp8CLiT6YD9\nS9KxiPhPWsVmfaqTB6qsAC6WXl8CHoyIHQCStgBXZgqSpG3ANoChoaEOyjDrD12bzYuI/RHx+1nW\n742IZkQ0ly+v9PRZs77WSZimgFWl1yuLtsr8fSYbJJ2E6UVgnaQ1khYBm4Aj7RzA32eyQVJ1avwA\n8Bxwj6RLkrZGxA1gB/AUcA44FBFn2zm570w2SKrO5m2eof0YcGyuJ6/6RFez+cAfJzJL4geqmCXx\nA1XMkribZ5bE3TyzJO7mmSVxN88sicNklsRjJrMkHjOZJXE3zyyJw2SWxGEyS+IJCLMknoAwS+Ju\nnlkSh8ksicNklsQTEGZJPAFhlsTdPLMkDpNZEofJLInDZJbEYTJL4jCZJXGYzJL4TVuzJH7T1iyJ\nu3lmSRwmsyQOk1mSTv7aulnfaOw8Oud9L+zemFKD70xmSRwmsyQOk1kSh8ksSXqYJH1U0hOSDkt6\nPPv4Zv2qUpgk7ZN0WdKZlvYRSeclTUjaCRAR5yJiO/AN4JP5JZv1p6p3pv3ASLlB0gJgD7ABGAY2\nSxou1j0CHAWOpVVq1ucqhSkiTgBXW5rXAxMRMRkR7wAHgdFi+yMRsQH4ZmaxZv2skzdtVwAXS68v\nAQ9K+gzwNWAxs9yZJG0DtgEMDQ11UIZZf0j/BEREHAeOV9huL7AXoNlsRnYdZr3WyWzeFLCq9Hpl\n0VaZv89kg6STML0IrJO0RtIiYBNwpJ0D+PtMNkiqTo0fAJ4D7pF0SdLWiLgB7ACeAs4BhyLibDsn\n953JBkmlMVNEbJ6h/RgdTH9HxBgw1mw2H5vrMcz6hT9OZJbED1QxS+IHqpglcTfPLIm7eWZJ3M0z\nSzLwD1Tphwdt2P8Hj5nMknjMZJbEYyazJO7mmSVxmMySeMxklsRjJrMk7uaZJXGYzJI4TGZJBv7j\nRJ3wR5GsHZ7NM0vi2TyzJB4zmSVxmMySeAKiT3nyY/5xmLqkkzDUee66gljn9cribp5ZEt+Z7BaD\ncIeoi99nMkvi95nMknjMZJbEYTJLooj6/wKmpLeAN2fZZBlwpUfltMN1tWc+1rU6IpZXOUhfhOl/\nkTQeEc2662jlutoz6HW5m2eWxGEySzJfwrS37gJm4LraM9B1zYsxk9l8MF/uTGZ9r+6PE41IOi9p\nQtLO26xfLOnJYv3zkhqldT8p2s9LeqjHdf1I0iuSXpb0J0mrS+velfRS8XOkx3VtkfRW6fzfLa17\nVNJrxc+jPa7rF6WaXpX099K6bl6vfZIuSzozw3pJ+mVR98uSHiita/96RUQtP8AC4HVgLbAI+DMw\n3LLN94EniuVNwJPF8nCx/WJgTXGcBT2s67PAB4vlx2/WVbz+R43Xawvwq9vsexcwWfy7tFhe2qu6\nWrb/IbCv29erOPangAeAMzOsfxj4AyDg48DznVyvOu9M64GJiJiMiHeAg8BoyzajwG+K5cPA5yWp\naD8YEdcj4g1gojheT+qKiGcj4p/Fy5PAyqRzd1TXLB4Cno6IqxHxN+BpYKSmujYDB5LOPauIOAFc\nnWWTUeC3Me0k8GFJdzPH61VnmFYAF0uvLxVtt90mIm4A14CPVNy3m3WVbWX6t9tNd0gal3RS0leS\namqnrq8XXZbDkla1uW8366LoDq8Bnik1d+t6VTFT7XO6Xv4+UwckfQtoAp8uNa+OiClJa4FnJJ2O\niNd7VNIYcCAirkv6HtN39c/16NxVbAIOR8S7pbY6r1eqOu9MU8Cq0uuVRdttt5G0EFgCvF1x327W\nhaQvALuARyLi+s32iJgq/p0EjgP396quiHi7VMuvgY9V3bebdZVsoqWL18XrVcVMtc/tenVr8Fdh\ncLiQ6YHdGt4buN7Xss0PuHUC4lCxfB+3TkBMkjcBUaWu+5kedK9raV8KLC6WlwGvMctgvAt13V1a\n/ipwMt4bUL9R1Le0WL6rV3UV290LXKB4b7Pb16t0jgYzT0Bs5NYJiBc6uV61hako+mHg1eI/5q6i\n7WdM/7YHuAP4HdMTDC8Aa0v77ir2Ow9s6HFdfwT+CrxU/Bwp2j8BnC7+Q50Gtva4rp8DZ4vzPwvc\nW9r3O8V1nAC+3cu6itc/BXa37Nft63UA+Avwb6bHPVuB7cD2Yr2APUXdp4FmJ9fLn4AwS+JPQJgl\ncZjMkjhMZkkcJrMkDpNZEofJLInDZJbEYTJL8l+0v/kvrSsFEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14f953550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACBpJREFUeJzt3V+MVHcZxvHvIwQaa4JUetEAy0Agrdur1gk1mvjfdClS\n1CYGoklRLFKtN96I4cZ4I3cmRpJmYwh6A0Wu2IBpqi3hprRdklqghHa7pQFipBQlMRoq9fViD+lh\nym7P7LwzZ3Z8Pslkz/mdf29O9tnzO7+ZOauIwMw695G6CzAbFA6TWRKHySyJw2SWxGEyS+IwmSVx\nmMySOExmSRwmsyTz6y4AYMmSJdFoNOouw+wDTpw4cTki7qyybl+EqdFoMD4+XncZZh8g6a2q67qb\nZ5ak1jBJ2iBp9OrVq3WWYZai1jBFxFhEbFu0aFGdZZil6It7pg/T2HF41tue27U+sRKz6fmeySyJ\nw2SWxGEyS+IwmSVxmMySOExmSfymrVkSv2lrlsTdPLMkDpNZEofJLInDZJbEYTJL4jCZJXGYzJI4\nTGZJuhImSbdLGpf0tW7s36wfVQqTpD2SLkk61dI+IumspAlJO0qLfgocyCzUrN9VvTLtBUbKDZLm\nAbuBdcAwsFnSsKSvAq8ClxLrNOt7lZ4BERHHJDVamtcCExExCSBpP7AR+BhwO1MB+7ekIxHx39Z9\nStoGbAMYGhqabf1mfaOTB6osBc6X5i8AD0TEEwCStgCXbxUkgIgYBUYBms2m/7GuzXldezpRROzt\n1r7N+lEno3kXgeWl+WVFW2X+PpMNkk7C9BKwRtJKSQuATcChdnbg7zPZIKk6NL4PeB64W9IFSVsj\n4jrwBPA0cAY4EBGn2zm4r0w2SKqO5m2epv0IcGS2B4+IMWCs2Ww+Ntt9mPULf5zILIkfqGKWxA9U\nMUvibp5ZEnfzzJK4m2eWxN08syTu5pklcTfPLIm7eWZJHCazJA6TWRIPQJgl8QCEWRJ388ySOExm\nSRwmsyQOk1kSj+aZJfFonlkSd/PMkjhMZkkcJrMkDpNZEofJLInDZJbE7zOZJfH7TGZJ3M0zS+Iw\nmSVxmMySdO1/2pr1UmPH4Vlve27X+pQafGUyS+IwmSVxmMySOExmSdLDJOmTkp6UdFDS49n7N+tX\nlcIkaY+kS5JOtbSPSDoraULSDoCIOBMR24FvAZ/NL9msP1W9Mu0FRsoNkuYBu4F1wDCwWdJwsexh\n4DBwJK1Ssz5XKUwRcQy40tK8FpiIiMmIeBfYD2ws1j8UEeuAb2cWa9bPOnnTdilwvjR/AXhA0heA\nbwILmeHKJGkbsA1gaGiogzLM+kP6JyAi4ihwtMJ6o8AoQLPZjOw6zHqtk9G8i8Dy0vyyoq0yf5/J\nBkknYXoJWCNppaQFwCbgUDs78PeZbJBUHRrfBzwP3C3pgqStEXEdeAJ4GjgDHIiI0+0c3FcmGySV\n7pkiYvM07UfoYPg7IsaAsWaz+dhs92HWL/xxIrMktX6fSdIGYMPq1au7dox++J6L/X/wA1XMkrib\nZ5bEz80zS+JunlkSd/PMkribZ5bE3TyzJO7mmSVxmMySOExmSTwAYZbEAxBmSfzg/hn4Q7LWDt8z\nmSVxmMySOExmSQb+y4F16eR+q06+15s9j+aZJfFont3EI5iz53smsyQOk1kSh8ksie+ZrC/M1dHP\nMl+ZzJL4fSZLMwhXl074fSazJO7mmSVxmMySOExmSRRR/7+TlfQ28NYMqywBLveonHa4rvbMxbpW\nRMSdVXbSF2H6MJLGI6JZdx2tXFd7Br0ud/PMkjhMZknmSphG6y5gGq6rPQNd15y4ZzKbC+bKlcms\n79X9RNcRSWclTUjacYvlCyU9VSx/QVKjtOxnRftZSQ/2uK6fSHpV0iuS/ixpRWnZe5JeLl6HelzX\nFklvl47//dKyRyW9Xrwe7XFdvyrV9Jqkf5SWdfN87ZF0SdKpaZZL0q+Lul+RdH9pWfvnKyJqeQHz\ngDeAVcAC4C/AcMs6PwSeLKY3AU8V08PF+guBlcV+5vWwri8CHy2mH79RVzH/zxrP1xbgN7fY9g5g\nsvi5uJhe3Ku6Wtb/MbCn2+er2PfngPuBU9Msfwj4IyDg08ALnZyvOq9Ma4GJiJiMiHeB/cDGlnU2\nAr8rpg8CX5akon1/RFyLiDeBiWJ/PakrIp6LiH8Vs8eBZUnH7qiuGTwIPBMRVyLi78AzwEhNdW0G\n9iUde0YRcQy4MsMqG4Hfx5TjwMcl3cUsz1edYVoKnC/NXyjabrlORFwHrgKfqLhtN+sq28rUX7cb\nbpM0Lum4pK8n1dROXY8UXZaDkpa3uW0366LoDq8Eni01d+t8VTFd7bM6X/6mbQckfQdoAp8vNa+I\niIuSVgHPSjoZEW/0qKQxYF9EXJP0A6au6l/q0bGr2AQcjIj3Sm11nq9UdV6ZLgLLS/PLirZbriNp\nPrAIeKfitt2sC0lfAXYCD0fEtRvtEXGx+DkJHAXu61VdEfFOqZbfAp+qum036yrZREsXr4vnq4rp\nap/d+erWzV+Fm8P5TN3YreT9G9d7W9b5ETcPQBwopu/l5gGISfIGIKrUdR9TN91rWtoXAwuL6SXA\n68xwM96Fuu4qTX8DOB7v31C/WdS3uJi+o1d1FevdA5yjeG+z2+erdIwG0w9ArOfmAYgXOzlftYWp\nKPoh4LXiF3Nn0fYLpv7aA9wG/IGpAYYXgVWlbXcW250F1vW4rj8BfwNeLl6HivbPACeLX6iTwNYe\n1/VL4HRx/OeAe0rbfq84jxPAd3tZVzH/c2BXy3bdPl/7gL8C/2HqvmcrsB3YXiwXsLuo+yTQ7OR8\n+RMQZkn8CQizJA6TWRKHySyJw2SWxGEyS+IwmSVxmMySOExmSf4Hs7npgIW69tIAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14f180150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14edfd190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nj+lgo27sJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14efe64d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14eade450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debias scores\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14ef64f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRwmsyT/A0HQ8rTRa0zkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14e8921d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvl4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14e620390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14e907b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACCBJREFUeJzt3V+MVGcdxvHvIwQaa4JUetHwbyBLWrdXrRNqNPG/6VKk\nqE3MEk2KYpEq3ngjhhvjjdyZGEmajSHoDRS5YgOmqbaEm9J2SWqBEtrtlgaIEShKYjRU6s+LPaSH\nKbs9u/ObOTPr80k2nHnPv19O9uG87zszZxURmFn7PlJ3AWZzhcNklsRhMkviMJklcZjMkjhMZkkc\nJrMkDpNZEofJLMn8ugsAWLJkSTQajbrLMPuAEydOXImIu6ts2xNhajQajI2N1V2G2QdIervqtu7m\nmSVxmMyS1BomSRskjVy7dq3OMsxS1DpmiohRYLTZbD4x3XaNHYdnfY5zu9bPel+zmXA3zyyJw2SW\nxGEyS+IwmSVxmMySOExmSfw+k1mSWsMUEaMRsXXRokV1lmGWwt08syQOk1kSh8ksicNklsRhMkvi\nMJklcZjMkjhMZkkcJrMkHQmTpDsljUn6WieOb9aLKoVJ0h5JlySdamkfknRW0rikHaVVPwUOZBZq\n1uuq3pn2AkPlBknzgN3AOmAQ2CRpUNJXgdeAS4l1mvW8Sg9UiYhjkhotzWuB8YiYAJC0H9gIfAy4\nk8mA/VvSkYj4b+sxJW0FtgKsWLFitvWb9Yx2nk60FDhfen0BeCgitgNI2gxcuV2QACJiBBgBaDab\n/ivV1vc69qiviNj7YdtI2gBsGBgY6FQZZl3TzmzeRWB56fWyoq0yf5/J5pJ2wvQysEbSKkkLgGHg\nUE5ZZv2n6tT4PuAF4F5JFyRtiYgbwHbgGeAMcCAiTs/k5P7aus0lVWfzNk3RfgQ4MtuTV308slk/\n8ANVzJL4gSpmSfxBV7Mk7uaZJXE3zyyJu3lmSRwmsyQeM5kl8ZjJLIm7eWZJHCazJB4zmSXxmMks\nibt5ZkkcJrMkDpNZEofJLIln88ySeDbPLIm7eWZJHCazJA6TWRKHySyJw2SWxGEyS+L3mcyS+H0m\nsyTu5pklcZjMkjhMZkkcJrMkDpNZEofJLInDZJak0p/hNOt1jR2HZ73vuV3rU2rwncksSXqYJH1S\n0lOSDkp6Mvv4Zr2qUpgk7ZF0SdKplvYhSWcljUvaARARZyJiG/At4LP5JZv1pqp3pr3AULlB0jxg\nN7AOGAQ2SRos1j0KHAaOpFVq1uMqhSkijgFXW5rXAuMRMRER7wL7gY3F9ociYh3w7amOKWmrpDFJ\nY5cvX55d9WY9pJ3ZvKXA+dLrC8BDkr4AfBNYyDR3pogYAUYAms1mtFGHWU9InxqPiKPA0SrbStoA\nbBgYGMguw6zr2pnNuwgsL71eVrRV5u8z2VzSTpheBtZIWiVpATAMHMopy6z/VJ0a3we8ANwr6YKk\nLRFxA9gOPAOcAQ5ExOmZnNxfW7e5pNKYKSI2TdF+hDamvyNiFBhtNptPzPYYZr3CD1QxS+IHqpgl\n8QddzZI4TGZJPGYyS+Ixk1kSd/PMkribZ5bE3TyzJO7mmSVxmMySzPlHffXCI6Ds/4MnIMySeALC\nLInHTGZJHCazJA6TWRJPQJgl8QSEWRJ388ySOExmSeb8JyD6VT9+cqOdmucCh2ka/fgLbfVxN88s\nie9MHdKvXZ5+rbsXOExzkANRD79pa5bEb9qaJfEEhFkSh8ksiSLq/3Oyki4Db0+zyRLgSpfKmQnX\nNTP9WNfKiLi7ykF6IkwfRtJYRDTrrqOV65qZuV6Xu3lmSRwmsyT9EqaRuguYguuamTldV1+Mmcz6\nQb/cmcx6Xt0fJxqSdFbSuKQdt1m/UNLTxfoXJTVK635WtJ+V9HCX6/qJpNckvSrpz5JWlta9J+mV\n4udQl+vaLOly6fzfL617XNIbxc/jXa7rV6WaXpf0j9K6Tl6vPZIuSTo1xXpJ+nVR96uSHiytm/n1\niohafoB5wJvAamAB8BdgsGWbHwJPFcvDwNPF8mCx/UJgVXGceV2s64vAR4vlJ2/WVbz+Z43XazPw\nm9vsexcwUfy7uFhe3K26Wrb/MbCn09erOPbngAeBU1OsfwT4IyDg08CL7VyvOu9Ma4HxiJiIiHeB\n/cDGlm02Ar8rlg8CX5akon1/RFyPiLeA8eJ4XakrIp6PiH8VL48Dy5LO3VZd03gYeDYirkbE34Fn\ngaGa6toE7Es697Qi4hhwdZpNNgK/j0nHgY9LuodZXq86w7QUOF96faFou+02EXEDuAZ8ouK+nayr\nbAuT/7vddIekMUnHJX09qaaZ1PVY0WU5KGn5DPftZF0U3eFVwHOl5k5dryqmqn1W18vfZ2qDpO8A\nTeDzpeaVEXFR0mrgOUknI+LNLpU0CuyLiOuSfsDkXf1LXTp3FcPAwYh4r9RW5/VKVeed6SKwvPR6\nWdF2220kzQcWAe9U3LeTdSHpK8BO4NGIuH6zPSIuFv9OAEeBB7pVV0S8U6rlt8Cnqu7bybpKhmnp\n4nXwelUxVe2zu16dGvxVGBzOZ3Jgt4r3B673t2zzI26dgDhQLN/PrRMQE+RNQFSp6wEmB91rWtoX\nAwuL5SXAG0wzGO9AXfeUlr8BHI/3B9RvFfUtLpbv6lZdxXb3Aeco3tvs9PUqnaPB1BMQ67l1AuKl\ndq5XbWEqin4EeL34xdxZtP2Cyf/tAe4A/sDkBMNLwOrSvjuL/c4C67pc15+AvwGvFD+HivbPACeL\nX6iTwJYu1/VL4HRx/ueB+0r7fq+4juPAd7tZV/H658Culv06fb32AX8F/sPkuGcLsA3YVqwXsLuo\n+yTQbOd6+RMQZkn8CQizJA6TWRKHySyJw2SWxGEyS+IwmSVxmMySOExmSf4HvhbtkoeQTD0AAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14e79ca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random scores\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14e2f42d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3Av6tfXXemYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14e56d790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6Cbc7JhpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14e2ed9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14dcd3750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb14db5b7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opts = {'log': True, 'normed': False}\n",
    "\n",
    "print('orig scores')\n",
    "for scores in orig_results:\n",
    "    plt.figure(figsize=(3,2))\n",
    "    plt.hist(scores, **opts)\n",
    "    plt.show()\n",
    "    \n",
    "print('debias scores')\n",
    "for scores in debias_results:\n",
    "    plt.figure(figsize=(3,2))\n",
    "    plt.hist(scores, **opts)\n",
    "    plt.show()\n",
    "    \n",
    "print('random scores')\n",
    "for scores in random_results:\n",
    "    plt.figure(figsize=(3,2))\n",
    "    plt.hist(scores, **opts)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.96897995365611589,\n",
       " 0.97703257241710084,\n",
       " 0.96907637628603738,\n",
       " 0.97677017808751421,\n",
       " 0.97493965659039661]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model_tool.compute_auc(test_sets[0]['is_toxic'], scores) for scores in orig_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.96566880771696162,\n",
       " 0.97167217662881655,\n",
       " 0.97509745977515871,\n",
       " 0.97394611471504855,\n",
       " 0.96275374082690013]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model_tool.compute_auc(test_sets[0]['is_toxic'], scores) for scores in debias_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.96533774663108818,\n",
       " 0.9758727856095335,\n",
       " 0.97477515920805546,\n",
       " 0.97448330699371499,\n",
       " 0.97095007421906943]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model_tool.compute_auc(test_sets[0]['is_toxic'], scores) for scores in random_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### looking at max per-example variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_test_set = test_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, orig_scores in enumerate(orig_results):\n",
    "    wiki_test_set['orig' + str(i)] = orig_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_test_set['orig_var'] = wiki_test_set[['orig0', 'orig1', 'orig2', 'orig3', 'orig4']].var(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_colwidth', 135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_toxic</th>\n",
       "      <th>orig0</th>\n",
       "      <th>orig1</th>\n",
       "      <th>orig2</th>\n",
       "      <th>orig3</th>\n",
       "      <th>orig4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15279</th>\n",
       "      <td>==supertall fag== fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15351</th>\n",
       "      <td>:I tried googling http://www.google.com/search?hl=nt&amp;lr;=&amp;q;=%22%D1%82%D0%B5%D0%BE%D0%B4%D0%BE%D1%80+%D0%94%D0%BE%D1%81%D1%82%D0%B...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11334</th>\n",
       "      <td>*** After all the times you have thwarted me... After all the times my plans for world domination were foiled by your meddlesome ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18786</th>\n",
       "      <td>== I despise the way you have treated my fellow Christian friend. ==  male   gay   married   a socialist   a vegetarian   We...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>June 2006 (UTC) : Faggot  01:07, 19</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27447</th>\n",
       "      <td>`, 21 June 2013 (UTC) :::Okay ima gey, god hate me brah   22:26`</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>:Nazism and religion Nazi mysticism Nazi architecture Category:Nazi physicians Nazi human experimentation Nazism and race Nazi so...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15197</th>\n",
       "      <td>Bollocks all is bollocks Bollocks all is bollocks Bollocks all is bollocks Bollocks all is bollocks Bollocks all is bollocks Bolloc...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>{{Infobox Anatomy |  Name         = Human penis |  Latin        = penis, penes |  GraySubject  = 262 |  GrayPage     = 1247 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117</th>\n",
       "      <td>PENIS SMACKING WILLY WANKING WILLY WONG</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.049</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31101</th>\n",
       "      <td>== You have got to be kidding  ==  (cur | prev) 17:11, 7 August 2015 Iridescent (talk | contribs) . . (131,644 bytes) (-22) . ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13357</th>\n",
       "      <td>LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12018</th>\n",
       "      <td>hiya hunnies! stuart isn't fat so be quiet xx</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18791</th>\n",
       "      <td>U FAT NOOB!!  I'm Samuel Gary Carter and I can't offend myself!!  I didn't add either of those pages  soo something must have ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>`  ==Bigot Alert!== {| align=``center`` class=``boilerplate metadata`` id=``stub`` CELLPADDING=3 CELLSPACING=3 width=80% style=``ba...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31666</th>\n",
       "      <td>REDIRECT Talk:American Landrace pig</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11811</th>\n",
       "      <td>, 28 February 2008 (UTC)  :::::The source is the United States Census Bureau you idiot.  Don't you even get it YET?    20:29</td>\n",
       "      <td>True</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>(UTC)  Ass hole -  17:53, 9 March 2007</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.297</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>btw mark arsten is a son of a bitch his cock is placed in a girls mouth  Hey guys I love chicken rice=)Hey guys I love chicken ric...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>`Here you go you Wikiholic nerds, I archived the stupid warning page, can I delete the Neversetwhaaaah thing, cuz it has been tagge...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20514</th>\n",
       "      <td>STUPID SPANISH CENTRALISTSTUPID SPANISH CENTRALISTSTUPID SPANISH CENTRALISTSTUPID SPANISH CENTRALISTSTUPID SPANISH CENTRALISTSTUPID...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19519</th>\n",
       "      <td>:Categories aren't substantial content. Only a moron would think so. -</td>\n",
       "      <td>True</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>==Iasi's population== Please participate to the discussion at Romania's talk page instead of writing your fucked arguments! '''''...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18079</th>\n",
       "      <td>Please choke on a bucket of dicks. Thank you.</td>\n",
       "      <td>True</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13888</th>\n",
       "      <td>` ::``happened 10 minutes ago``  Happened ten minutes ago where?  On TV.  TV *IS* MEDIA retard you mentally incapacitated person.  ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21394</th>\n",
       "      <td>` {| width=``75%`` align=``center`` class=``notice noprint`` style=``background: none; border: 1px solid #aaa; padding: 0.5em; marg...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22599</th>\n",
       "      <td>:If you'd ever had heroin-coated condoms during anal sex with infant koalas then you wouldn't dispute its popularity  Philipbeswi...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29965</th>\n",
       "      <td>== Health Issues? ==  Health issues are keeping you away? What, are you sick to your stomach because I exposed your corruption?</td>\n",
       "      <td>False</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24933</th>\n",
       "      <td>Erik, the word came down the food chain from the top.  follow the money(funding) to the circumcision lobby to find out why jimbo ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>http://en.wikipedia.org/w/index.php?title=Wikipedia%3AChanging_username&amp;diff;=92790566&amp;oldid;=92769124 never come back, or else you...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>== fuck you  ==  fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28531</th>\n",
       "      <td>is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>fuck you.  your fuckin stupid and i'm black and fuck you fuck uou sdjasf;ldjgs dgsdg;lknfdts</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>== YOU LIKE COCK 8==========D - - - - - ==    NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19866</th>\n",
       "      <td>== ADMINS SUCK!! ==  THE FUCKING ADMINS SUCK ASS! I FUCKING HATE THE PEOPLE WHO DELETE MY FUCKING SHIT!!!!!!!!</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12743</th>\n",
       "      <td>== Twat ==  You're a fucking cunt</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13170</th>\n",
       "      <td>FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16389</th>\n",
       "      <td>SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COC...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29958</th>\n",
       "      <td>== Requested move 6 January 2015 ==    :Valmiki    All indian colleges,hospitals and academy describes him as Maharshi Valmiki,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>== Bastard ==  You fat bastard! You have done it! Your end will come! Blood from your throat! Death in the air! And the DN group ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28365</th>\n",
       "      <td>Hanibal911You're a bastard Pro-Assad.Hanibal911You're a bastard Pro-Assad.Hanibal911You're a bastard Pro-Assad.Hanibal911You're a...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12094</th>\n",
       "      <td>== wtf ==  fuck this shit why the fuck wuld sum pussy liccking site be fucking offline? FUCK!</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12095</th>\n",
       "      <td>==Fuck You==  I don't need you to unblock me you fucking idiot, you have some tea</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19779</th>\n",
       "      <td>U MAD?  I'll fuck you blind bitch. I'll fuck you blind till you just can't see no more.         Sit on my dick, fart on my ballls. ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12102</th>\n",
       "      <td>== How About You Shut the Fuck Up? ==  Stop fucking with my posts you fucking douche bag  I AM Joe Torres. Leave me be.</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19808</th>\n",
       "      <td>ur a faggot, fuck off and get a real job and stop fucking with my posts   8=======D</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12108</th>\n",
       "      <td>= fuck you, whores!!! I'LL FUCK YOU UP OLD-STYLE, MOTHERFUCKING TRANNYBANGERS CUNTS! =</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12903</th>\n",
       "      <td>== Suck it bitch!!!!!!! ==  ha ha bitch fuck!!!!!</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23183</th>\n",
       "      <td>fuck cocksucker titty marijuana nigger whore</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16310</th>\n",
       "      <td>==asshole== fuck u asshole go fucking rape my penis</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27699</th>\n",
       "      <td>:Fuck you all, antisemitic faggots.</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9840</th>\n",
       "      <td>Go fuck yourself!!! you fucking delteted it anyway! whats the fucking point of a public Encyclopedia if you delete evrything!?!?!...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8035</th>\n",
       "      <td>Hey Fuck u bitch...i dont suck nuts \\, linkin park does!</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>`:::You fucking retards, only a fucking dumbshit would be religious. Does Godel look like a fucking dumbshit? \\/  `</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27688</th>\n",
       "      <td>` == Your submission at AfC Saint Michaels Township, Madison County, Missouri was accepted ==  Saint Michaels Township, Madison Cou...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10596</th>\n",
       "      <td>`{| style=``background-color:#F5FFFA; padding:0;`` cellpadding=``0`` |class=``MainPageBG`` style=``border:1px solid #084080; backgr...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Yeah. go suck dick u corrupt retarded fat pig Homo.</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21434</th>\n",
       "      <td>You're an asshole, useless piece of shit. Get a life, motherfucker!</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>Jetstreamer: you can go and fuck yourself you stupid sick bastard homo!</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30208</th>\n",
       "      <td>Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat c...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31866 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                      comment  \\\n",
       "15279    ==supertall fag== fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag fag...   \n",
       "15351   :I tried googling http://www.google.com/search?hl=nt&lr;=&q;=%22%D1%82%D0%B5%D0%BE%D0%B4%D0%BE%D1%80+%D0%94%D0%BE%D1%81%D1%82%D0%B...   \n",
       "11334    *** After all the times you have thwarted me... After all the times my plans for world domination were foiled by your meddlesome ...   \n",
       "18786    == I despise the way you have treated my fellow Christian friend. ==  male   gay   married   a socialist   a vegetarian   We...   \n",
       "3696                                                                                                      June 2006 (UTC) : Faggot  01:07, 19   \n",
       "27447                                                                        `, 21 June 2013 (UTC) :::Okay ima gey, god hate me brah   22:26`   \n",
       "3658     :Nazism and religion Nazi mysticism Nazi architecture Category:Nazi physicians Nazi human experimentation Nazism and race Nazi so...   \n",
       "15197  Bollocks all is bollocks Bollocks all is bollocks Bollocks all is bollocks Bollocks all is bollocks Bollocks all is bollocks Bolloc...   \n",
       "16996         {{Infobox Anatomy |  Name         = Human penis |  Latin        = penis, penes |  GraySubject  = 262 |  GrayPage     = 1247 ...   \n",
       "4117                                                                                                  PENIS SMACKING WILLY WANKING WILLY WONG   \n",
       "31101    == You have got to be kidding  ==  (cur | prev) 17:11, 7 August 2015 Iridescent (talk | contribs) . . (131,644 bytes) (-22) . ...   \n",
       "13357  LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL...   \n",
       "12018                                                                                           hiya hunnies! stuart isn't fat so be quiet xx   \n",
       "18791       U FAT NOOB!!  I'm Samuel Gary Carter and I can't offend myself!!  I didn't add either of those pages  soo something must have ...   \n",
       "6820   `  ==Bigot Alert!== {| align=``center`` class=``boilerplate metadata`` id=``stub`` CELLPADDING=3 CELLSPACING=3 width=80% style=``ba...   \n",
       "31666                                                                                                    REDIRECT Talk:American Landrace pig    \n",
       "11811            , 28 February 2008 (UTC)  :::::The source is the United States Census Bureau you idiot.  Don't you even get it YET?    20:29   \n",
       "7347                                                                                                   (UTC)  Ass hole -  17:53, 9 March 2007   \n",
       "24349   btw mark arsten is a son of a bitch his cock is placed in a girls mouth  Hey guys I love chicken rice=)Hey guys I love chicken ric...   \n",
       "5459   `Here you go you Wikiholic nerds, I archived the stupid warning page, can I delete the Neversetwhaaaah thing, cuz it has been tagge...   \n",
       "20514  STUPID SPANISH CENTRALISTSTUPID SPANISH CENTRALISTSTUPID SPANISH CENTRALISTSTUPID SPANISH CENTRALISTSTUPID SPANISH CENTRALISTSTUPID...   \n",
       "19519                                                                :Categories aren't substantial content. Only a moron would think so. -     \n",
       "3583     ==Iasi's population== Please participate to the discussion at Romania's talk page instead of writing your fucked arguments! '''''...   \n",
       "18079                                                                                           Please choke on a bucket of dicks. Thank you.   \n",
       "13888  ` ::``happened 10 minutes ago``  Happened ten minutes ago where?  On TV.  TV *IS* MEDIA retard you mentally incapacitated person.  ...   \n",
       "21394  ` {| width=``75%`` align=``center`` class=``notice noprint`` style=``background: none; border: 1px solid #aaa; padding: 0.5em; marg...   \n",
       "22599    :If you'd ever had heroin-coated condoms during anal sex with infant koalas then you wouldn't dispute its popularity  Philipbeswi...   \n",
       "29965      == Health Issues? ==  Health issues are keeping you away? What, are you sick to your stomach because I exposed your corruption?      \n",
       "24933    Erik, the word came down the food chain from the top.  follow the money(funding) to the circumcision lobby to find out why jimbo ...   \n",
       "6173   http://en.wikipedia.org/w/index.php?title=Wikipedia%3AChanging_username&diff;=92790566&oldid;=92769124 never come back, or else you...   \n",
       "...                                                                                                                                       ...   \n",
       "1768     == fuck you  ==  fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck you fuck...   \n",
       "28531   is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; is a shit. ; ...   \n",
       "6568                                             fuck you.  your fuckin stupid and i'm black and fuck you fuck uou sdjasf;ldjgs dgsdg;lknfdts   \n",
       "896      == YOU LIKE COCK 8==========D - - - - - ==    NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER NIGGER...   \n",
       "19866                          == ADMINS SUCK!! ==  THE FUCKING ADMINS SUCK ASS! I FUCKING HATE THE PEOPLE WHO DELETE MY FUCKING SHIT!!!!!!!!   \n",
       "12743                                                                                                       == Twat ==  You're a fucking cunt   \n",
       "13170  FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT JEW FAT...   \n",
       "16389  SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COCK D SUCK MY COC...   \n",
       "29958    == Requested move 6 January 2015 ==    :Valmiki    All indian colleges,hospitals and academy describes him as Maharshi Valmiki,...   \n",
       "3089     == Bastard ==  You fat bastard! You have done it! Your end will come! Blood from your throat! Death in the air! And the DN group ...   \n",
       "28365    Hanibal911You're a bastard Pro-Assad.Hanibal911You're a bastard Pro-Assad.Hanibal911You're a bastard Pro-Assad.Hanibal911You're a...   \n",
       "12094                                        == wtf ==  fuck this shit why the fuck wuld sum pussy liccking site be fucking offline? FUCK!      \n",
       "12095                                                     ==Fuck You==  I don't need you to unblock me you fucking idiot, you have some tea     \n",
       "19779  U MAD?  I'll fuck you blind bitch. I'll fuck you blind till you just can't see no more.         Sit on my dick, fart on my ballls. ...   \n",
       "12102                 == How About You Shut the Fuck Up? ==  Stop fucking with my posts you fucking douche bag  I AM Joe Torres. Leave me be.   \n",
       "19808                                                     ur a faggot, fuck off and get a real job and stop fucking with my posts   8=======D   \n",
       "12108                                                  = fuck you, whores!!! I'LL FUCK YOU UP OLD-STYLE, MOTHERFUCKING TRANNYBANGERS CUNTS! =   \n",
       "12903                                                                                     == Suck it bitch!!!!!!! ==  ha ha bitch fuck!!!!!     \n",
       "23183                                                                                            fuck cocksucker titty marijuana nigger whore   \n",
       "16310                                                                                     ==asshole== fuck u asshole go fucking rape my penis   \n",
       "27699                                                                                                  :Fuck you all, antisemitic faggots.      \n",
       "9840     Go fuck yourself!!! you fucking delteted it anyway! whats the fucking point of a public Encyclopedia if you delete evrything!?!?!...   \n",
       "8035                                                                                 Hey Fuck u bitch...i dont suck nuts \\, linkin park does!   \n",
       "12118                   `:::You fucking retards, only a fucking dumbshit would be religious. Does Godel look like a fucking dumbshit? \\/  `   \n",
       "27688  ` == Your submission at AfC Saint Michaels Township, Madison County, Missouri was accepted ==  Saint Michaels Township, Madison Cou...   \n",
       "10596  `{| style=``background-color:#F5FFFA; padding:0;`` cellpadding=``0`` |class=``MainPageBG`` style=``border:1px solid #084080; backgr...   \n",
       "9088                                                                                    Yeah. go suck dick u corrupt retarded fat pig Homo.     \n",
       "21434                                                                     You're an asshole, useless piece of shit. Get a life, motherfucker!   \n",
       "29089                                                                 Jetstreamer: you can go and fuck yourself you stupid sick bastard homo!   \n",
       "30208   Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat cunt. Im a fat c...   \n",
       "\n",
       "       is_toxic  orig0  orig1  orig2  orig3  orig4  \n",
       "15279      True  1.000  1.000  0.000  1.000  0.000  \n",
       "15351     False  0.000  1.000  0.000  1.000  0.000  \n",
       "11334      True  0.000  1.000  0.000  1.000  0.000  \n",
       "18786      True  0.000  1.000  0.001  1.000  0.003  \n",
       "3696       True  0.000  1.000  0.000  1.000  0.006  \n",
       "27447      True  0.000  0.987  0.001  0.992  0.000  \n",
       "3658       True  0.003  0.055  0.000  0.853  0.985  \n",
       "15197      True  0.046  0.967  0.300  1.000  0.999  \n",
       "16996     False  0.000  0.542  0.000  1.000  0.000  \n",
       "4117       True  1.000  1.000  0.049  1.000  0.970  \n",
       "31101      True  0.000  0.893  0.000  0.604  0.690  \n",
       "13357     False  0.013  0.398  0.228  0.952  0.004  \n",
       "12018     False  0.011  0.882  0.006  0.118  0.213  \n",
       "18791      True  0.000  0.829  0.000  0.099  0.087  \n",
       "6820       True  0.091  0.992  0.468  0.834  0.629  \n",
       "31666      True  0.003  0.020  0.000  0.270  0.797  \n",
       "11811      True  0.028  0.624  0.617  0.926  0.558  \n",
       "7347       True  0.999  1.000  0.297  1.000  0.991  \n",
       "24349      True  0.966  0.901  0.247  0.443  0.572  \n",
       "5459      False  0.000  0.335  0.171  0.746  0.035  \n",
       "20514      True  0.370  0.092  0.000  0.685  0.602  \n",
       "19519      True  0.023  0.050  0.737  0.282  0.453  \n",
       "3583       True  0.070  0.859  0.598  0.376  0.532  \n",
       "18079      True  0.742  0.093  0.821  0.523  0.692  \n",
       "13888      True  0.174  0.527  0.805  0.920  0.681  \n",
       "21394      True  0.003  0.000  0.614  0.397  0.001  \n",
       "22599      True  0.000  0.323  0.702  0.127  0.046  \n",
       "29965     False  0.200  0.811  0.754  0.895  0.522  \n",
       "24933     False  0.063  0.302  0.456  0.782  0.548  \n",
       "6173       True  0.000  0.609  0.629  0.392  0.586  \n",
       "...         ...    ...    ...    ...    ...    ...  \n",
       "1768       True  1.000  1.000  1.000  1.000  1.000  \n",
       "28531      True  1.000  1.000  1.000  1.000  1.000  \n",
       "6568       True  1.000  1.000  1.000  1.000  1.000  \n",
       "896        True  1.000  1.000  1.000  1.000  1.000  \n",
       "19866      True  1.000  1.000  1.000  1.000  1.000  \n",
       "12743      True  1.000  1.000  1.000  1.000  1.000  \n",
       "13170      True  1.000  1.000  1.000  1.000  1.000  \n",
       "16389      True  1.000  1.000  1.000  1.000  1.000  \n",
       "29958     False  0.000  0.000  0.000  0.000  0.000  \n",
       "3089       True  1.000  1.000  1.000  1.000  1.000  \n",
       "28365      True  1.000  1.000  1.000  1.000  1.000  \n",
       "12094      True  1.000  1.000  1.000  1.000  1.000  \n",
       "12095      True  1.000  1.000  1.000  1.000  1.000  \n",
       "19779      True  1.000  1.000  1.000  1.000  1.000  \n",
       "12102      True  1.000  1.000  1.000  1.000  1.000  \n",
       "19808      True  1.000  1.000  1.000  1.000  1.000  \n",
       "12108      True  1.000  1.000  1.000  1.000  1.000  \n",
       "12903      True  1.000  1.000  1.000  1.000  1.000  \n",
       "23183      True  1.000  1.000  1.000  1.000  1.000  \n",
       "16310      True  1.000  1.000  1.000  1.000  1.000  \n",
       "27699      True  1.000  1.000  1.000  1.000  1.000  \n",
       "9840       True  1.000  1.000  1.000  1.000  1.000  \n",
       "8035       True  1.000  1.000  1.000  1.000  1.000  \n",
       "12118      True  1.000  1.000  1.000  1.000  1.000  \n",
       "27688     False  0.000  0.000  0.000  0.000  0.000  \n",
       "10596     False  0.000  0.000  0.000  0.000  0.000  \n",
       "9088       True  1.000  1.000  1.000  1.000  1.000  \n",
       "21434      True  1.000  1.000  1.000  1.000  1.000  \n",
       "29089      True  1.000  1.000  1.000  1.000  1.000  \n",
       "30208      True  1.000  1.000  1.000  1.000  1.000  \n",
       "\n",
       "[31866 rows x 7 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_test_set.sort_values('orig_var', ascending=False)[['comment', 'is_toxic', 'orig0', 'orig1', 'orig2', 'orig3', 'orig4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"     U FAT NOOB!!  I'm Samuel Gary Carter and I can't offend myself!!  I didn't add either of those pages  soo something must have hacked into mya ccount  and done i tthere\""
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_test_set.loc[18791].comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hack 2: more regularization (dropout 0.1 -> 0.3, epochs 3 -> 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training wiki model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This: :One can make an analogy in mathematical...\n",
       "1    `  :Clarification for you  (and Zundark's righ...\n",
       "2    `This is such a fun entry.   Devotchka  I once...\n",
       "3    `   I fixed the link; I also removed ``homeopa...\n",
       "4    `If they are ``indisputable`` then why does th...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_train_comments = pd.read_csv(wiki['train'])['comment']\n",
    "wiki_train_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    95692.000000\n",
       "mean       401.608818\n",
       "std        598.384488\n",
       "min          5.000000\n",
       "50%        211.000000\n",
       "75%        444.000000\n",
       "90%        898.000000\n",
       "95%       1380.000000\n",
       "99%       3503.270000\n",
       "max       5900.000000\n",
       "Name: comment, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_train_comments.str.len().describe(percentiles=[0.5, .75, .9, 0.95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki: {'test': '../data/wiki_test.csv', 'train': '../data/wiki_train.csv', 'dev': '../data/wiki_dev.csv'}\n",
      "\n",
      "\n",
      " ======= training hack2_orig_v0 2017-10-04 13:22:54.821579\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/5\n",
      "95692/95692 [==============================] - 597s - loss: 0.1486 - acc: 0.9483 - val_loss: 0.1118 - val_acc: 0.9564\n",
      "Epoch 2/5\n",
      "95692/95692 [==============================] - 602s - loss: 0.1033 - acc: 0.9634 - val_loss: 0.1340 - val_acc: 0.9615\n",
      "Epoch 3/5\n",
      "95692/95692 [==============================] - 603s - loss: 0.0928 - acc: 0.9663 - val_loss: 0.1114 - val_acc: 0.9629\n",
      "Epoch 4/5\n",
      "95692/95692 [==============================] - 600s - loss: 0.0866 - acc: 0.9689 - val_loss: 0.1102 - val_acc: 0.9634\n",
      "Epoch 5/5\n",
      "95692/95692 [==============================] - 595s - loss: 0.0807 - acc: 0.9711 - val_loss: 0.1448 - val_acc: 0.9628\n",
      "<keras.callbacks.History object at 0x7f1abeabb410>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "\n",
      "\n",
      " ======= training hack2_orig_v1 2017-10-04 14:13:17.012569\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/5\n",
      "95692/95692 [==============================] - 597s - loss: 0.1477 - acc: 0.9487 - val_loss: 0.1044 - val_acc: 0.9626\n",
      "Epoch 2/5\n",
      "95692/95692 [==============================] - 595s - loss: 0.1025 - acc: 0.9630 - val_loss: 0.1122 - val_acc: 0.9581\n",
      "Epoch 3/5\n",
      "95692/95692 [==============================] - 598s - loss: 0.0918 - acc: 0.9673 - val_loss: 0.1185 - val_acc: 0.9609\n",
      "Epoch 4/5\n",
      "95692/95692 [==============================] - 600s - loss: 0.0842 - acc: 0.9699 - val_loss: 0.1212 - val_acc: 0.9627\n",
      "Epoch 5/5\n",
      "95692/95692 [==============================] - 620s - loss: 0.0766 - acc: 0.9733 - val_loss: 0.1243 - val_acc: 0.9631\n",
      "<keras.callbacks.History object at 0x7f1a9297e7d0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "\n",
      "\n",
      " ======= training hack2_orig_v2 2017-10-04 15:03:54.765847\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/5\n",
      "95692/95692 [==============================] - 620s - loss: 0.1496 - acc: 0.9467 - val_loss: 0.1288 - val_acc: 0.9625\n",
      "Epoch 2/5\n",
      "95692/95692 [==============================] - 596s - loss: 0.1027 - acc: 0.9630 - val_loss: 0.1000 - val_acc: 0.9638\n",
      "Epoch 3/5\n",
      "95692/95692 [==============================] - 586s - loss: 0.0932 - acc: 0.9661 - val_loss: 0.1127 - val_acc: 0.9629\n",
      "Epoch 4/5\n",
      "92800/95692 [============================>.] - ETA: 16s - loss: 0.0856 - acc: 0.9694"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-48f982b9ff5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"\\nimport datetime\\n\\nprint('wiki:', wiki)\\n\\nhack2_wiki_models = []\\n\\nfor i in xrange(4):\\n    name = 'hack2_orig_v{}'.format(i)\\n    print('\\\\n\\\\n ======= training', name, datetime.datetime.now())\\n    model = ToxModel()\\n    model.train(wiki['train'], wiki['dev'], text_column='comment', label_column='is_toxic', model_name=name)\\n    hack2_wiki_models.append((name, model))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/src/model_tool.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data_path, validation_data_path, text_column, label_column, model_name)\u001b[0m\n\u001b[1;32m    133\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m           validation_data=(valid_data, valid_labels)))\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model trained!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "\n",
    "print('wiki:', wiki)\n",
    "\n",
    "hack2_wiki_models = []\n",
    "\n",
    "for i in xrange(4):\n",
    "    name = 'hack2_orig_v{}'.format(i)\n",
    "    print('\\n\\n ======= training', name, datetime.datetime.now())\n",
    "    model = ToxModel()\n",
    "    model.train(wiki['train'], wiki['dev'], text_column='comment', label_column='is_toxic', model_name=name)\n",
    "    hack2_wiki_models.append((name, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hack 3: limit features (max_sequence_length 1000 -> 250)\n",
    "\n",
    "epochs lowered to 4 to get more runs faster.\n",
    "dropout still set to 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki: {'test': '../data/wiki_test.csv', 'train': '../data/wiki_train.csv', 'dev': '../data/wiki_dev.csv'}\n",
      "\n",
      "\n",
      " ======= training hack3_orig_v0 2017-10-04 15:53:40.278734\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/4\n",
      "95692/95692 [==============================] - 196s - loss: 0.1495 - acc: 0.9469 - val_loss: 0.1054 - val_acc: 0.9623\n",
      "Epoch 2/4\n",
      "95692/95692 [==============================] - 195s - loss: 0.1056 - acc: 0.9629 - val_loss: 0.1054 - val_acc: 0.9634\n",
      "Epoch 3/4\n",
      "95692/95692 [==============================] - 196s - loss: 0.0949 - acc: 0.9665 - val_loss: 0.1057 - val_acc: 0.9618\n",
      "Epoch 4/4\n",
      "95692/95692 [==============================] - 196s - loss: 0.0866 - acc: 0.9697 - val_loss: 0.1394 - val_acc: 0.9595\n",
      "<keras.callbacks.History object at 0x7fd9ab43b450>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "\n",
      "\n",
      " ======= training hack3_orig_v1 2017-10-04 16:07:09.092612\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/4\n",
      "95692/95692 [==============================] - 199s - loss: 0.1500 - acc: 0.9473 - val_loss: 0.1085 - val_acc: 0.9596\n",
      "Epoch 2/4\n",
      "95692/95692 [==============================] - 200s - loss: 0.1046 - acc: 0.9629 - val_loss: 0.1029 - val_acc: 0.9635\n",
      "Epoch 3/4\n",
      "95692/95692 [==============================] - 197s - loss: 0.0946 - acc: 0.9668 - val_loss: 0.1087 - val_acc: 0.9630\n",
      "Epoch 4/4\n",
      "95692/95692 [==============================] - 196s - loss: 0.0854 - acc: 0.9697 - val_loss: 0.1136 - val_acc: 0.9624\n",
      "<keras.callbacks.History object at 0x7fd97c70e7d0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "\n",
      "\n",
      " ======= training hack3_orig_v2 2017-10-04 16:20:47.195339\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/4\n",
      "95692/95692 [==============================] - 197s - loss: 0.1504 - acc: 0.9467 - val_loss: 0.1093 - val_acc: 0.9625\n",
      "Epoch 2/4\n",
      "95692/95692 [==============================] - 200s - loss: 0.1048 - acc: 0.9632 - val_loss: 0.1304 - val_acc: 0.9590\n",
      "Epoch 3/4\n",
      "68480/95692 [====================>.........] - ETA: 52s - loss: 0.0956 - acc: 0.9662"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "\n",
    "print('wiki:', wiki)\n",
    "\n",
    "hack3_wiki_models = []\n",
    "\n",
    "for i in xrange(4):\n",
    "    name = 'hack3_orig_v{}'.format(i)\n",
    "    print('\\n\\n ======= training', name, datetime.datetime.now())\n",
    "    model = ToxModel()\n",
    "    model.train(wiki['train'], wiki['dev'], text_column='comment', label_column='is_toxic', model_name=name)\n",
    "    hack3_wiki_models.append((name, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hack4: limit num words and sequence length\n",
    "\n",
    "- num_words: 5000 (was 20k)\n",
    "- sequence length: 250 (same as hack3, was 1000 originally)\n",
    "- epochs: 4 (same as hack3)\n",
    "- dropout: 0.3 (same as hack3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki: {'test': '../data/wiki_test.csv', 'train': '../data/wiki_train.csv', 'dev': '../data/wiki_dev.csv'}\n",
      "\n",
      "\n",
      " ======= training hack4_orig_v0 2017-10-04 16:31:43.819996\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/4\n",
      "95692/95692 [==============================] - 200s - loss: 0.1539 - acc: 0.9476 - val_loss: 0.1175 - val_acc: 0.9594\n",
      "Epoch 2/4\n",
      "95692/95692 [==============================] - 199s - loss: 0.1117 - acc: 0.9614 - val_loss: 0.1101 - val_acc: 0.9597\n",
      "Epoch 3/4\n",
      "95692/95692 [==============================] - 198s - loss: 0.1028 - acc: 0.9630 - val_loss: 0.1106 - val_acc: 0.9622\n",
      "Epoch 4/4\n",
      "95692/95692 [==============================] - 196s - loss: 0.0986 - acc: 0.9656 - val_loss: 0.1472 - val_acc: 0.9612\n",
      "<keras.callbacks.History object at 0x7f8b4005b450>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "\n",
      "\n",
      " ======= training hack4_orig_v1 2017-10-04 16:45:21.894337\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/4\n",
      "95692/95692 [==============================] - 197s - loss: 0.1554 - acc: 0.9473 - val_loss: 0.1127 - val_acc: 0.9574\n",
      "Epoch 2/4\n",
      "95692/95692 [==============================] - 197s - loss: 0.1132 - acc: 0.9605 - val_loss: 0.1491 - val_acc: 0.9564\n",
      "Epoch 3/4\n",
      "95692/95692 [==============================] - 200s - loss: 0.1061 - acc: 0.9628 - val_loss: 0.1189 - val_acc: 0.9596\n",
      "Epoch 4/4\n",
      "95692/95692 [==============================] - 200s - loss: 0.1014 - acc: 0.9645 - val_loss: 0.1220 - val_acc: 0.9608\n",
      "<keras.callbacks.History object at 0x7f89f267e850>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "\n",
      "\n",
      " ======= training hack4_orig_v2 2017-10-04 16:59:01.541888\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/4\n",
      "95692/95692 [==============================] - 202s - loss: 0.1546 - acc: 0.9471 - val_loss: 0.1174 - val_acc: 0.9598\n",
      "Epoch 2/4\n",
      "95692/95692 [==============================] - 200s - loss: 0.1143 - acc: 0.9609 - val_loss: 0.1199 - val_acc: 0.9560\n",
      "Epoch 3/4\n",
      "42880/95692 [============>.................] - ETA: 103s - loss: 0.1022 - acc: 0.9643"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a836d2f10a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"\\nimport datetime\\n\\nprint('wiki:', wiki)\\n\\nhack4_wiki_models = []\\n\\nfor i in xrange(4):\\n    name = 'hack4_orig_v{}'.format(i)\\n    print('\\\\n\\\\n ======= training', name, datetime.datetime.now())\\n    model = ToxModel()\\n    model.train(wiki['train'], wiki['dev'], text_column='comment', label_column='is_toxic', model_name=name)\\n    hack4_wiki_models.append((name, model))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/src/model_tool.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data_path, validation_data_path, text_column, label_column, model_name)\u001b[0m\n\u001b[1;32m    135\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m           validation_data=(valid_data, valid_labels)))\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model trained!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "\n",
    "print('wiki:', wiki)\n",
    "\n",
    "hack4_wiki_models = []\n",
    "\n",
    "for i in xrange(4):\n",
    "    name = 'hack4_orig_v{}'.format(i)\n",
    "    print('\\n\\n ======= training', name, datetime.datetime.now())\n",
    "    model = ToxModel()\n",
    "    model.train(wiki['train'], wiki['dev'], text_column='comment', label_column='is_toxic', model_name=name)\n",
    "    hack4_wiki_models.append((name, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hack5: more epochs to track training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki: {'test': '../data/wiki_test.csv', 'train': '../data/wiki_train.csv', 'dev': '../data/wiki_dev.csv'}\n",
      "\n",
      "\n",
      " ======= training hack5_orig_v0 2017-10-04 17:07:59.615156\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/10\n",
      "95692/95692 [==============================] - 200s - loss: 0.1542 - acc: 0.9458 - val_loss: 0.1316 - val_acc: 0.9543\n",
      "Epoch 2/10\n",
      "95692/95692 [==============================] - 199s - loss: 0.1120 - acc: 0.9614 - val_loss: 0.1169 - val_acc: 0.9558\n",
      "Epoch 3/10\n",
      "95692/95692 [==============================] - 200s - loss: 0.1046 - acc: 0.9634 - val_loss: 0.1207 - val_acc: 0.9604\n",
      "Epoch 4/10\n",
      "95692/95692 [==============================] - 206s - loss: 0.1028 - acc: 0.9652 - val_loss: 0.1270 - val_acc: 0.9609\n",
      "Epoch 5/10\n",
      "95692/95692 [==============================] - 205s - loss: 0.1000 - acc: 0.9663 - val_loss: 0.1489 - val_acc: 0.9612\n",
      "Epoch 6/10\n",
      "95692/95692 [==============================] - 207s - loss: 0.0962 - acc: 0.9686 - val_loss: 0.1476 - val_acc: 0.9520\n",
      "Epoch 7/10\n",
      "95692/95692 [==============================] - 209s - loss: 0.0855 - acc: 0.9716 - val_loss: 0.1585 - val_acc: 0.9594\n",
      "Epoch 8/10\n",
      "18176/95692 [====>.........................] - ETA: 155s - loss: 0.0752 - acc: 0.9745"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1c51124862ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"\\nimport datetime\\n\\nprint('wiki:', wiki)\\n\\nhack5_wiki_models = []\\n\\nfor i in xrange(4):\\n    name = 'hack5_orig_v{}'.format(i)\\n    print('\\\\n\\\\n ======= training', name, datetime.datetime.now())\\n    model = ToxModel()\\n    model.train(wiki['train'], wiki['dev'], text_column='comment', label_column='is_toxic', model_name=name)\\n    hack5_wiki_models.append((name, model))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/src/model_tool.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data_path, validation_data_path, text_column, label_column, model_name)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         print(self.model.fit(train_data, train_labels,\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "\n",
    "print('wiki:', wiki)\n",
    "\n",
    "hack5_wiki_models = []\n",
    "\n",
    "for i in xrange(4):\n",
    "    name = 'hack5_orig_v{}'.format(i)\n",
    "    print('\\n\\n ======= training', name, datetime.datetime.now())\n",
    "    model = ToxModel()\n",
    "    model.train(wiki['train'], wiki['dev'], text_column='comment', label_column='is_toxic', model_name=name)\n",
    "    hack5_wiki_models.append((name, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hack6: lower learning rate\n",
    "\n",
    "- seq len: 250\n",
    "- num words: 5000\n",
    "- epochs: 8\n",
    "- dropout: 0.3\n",
    "- learn rate 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki: {'test': '../data/wiki_test.csv', 'train': '../data/wiki_train.csv', 'dev': '../data/wiki_dev.csv'}\n",
      "\n",
      "\n",
      " ======= training hack6_orig_v0 2017-10-04 17:34:20.457466\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/8\n",
      "95692/95692 [==============================] - 128s - loss: 0.2102 - acc: 0.9262 - val_loss: 0.1549 - val_acc: 0.9433\n",
      "Epoch 2/8\n",
      "95692/95692 [==============================] - 123s - loss: 0.1505 - acc: 0.9454 - val_loss: 0.1413 - val_acc: 0.9495\n",
      "Epoch 3/8\n",
      "95692/95692 [==============================] - 125s - loss: 0.1327 - acc: 0.9522 - val_loss: 0.1344 - val_acc: 0.9525\n",
      "Epoch 4/8\n",
      "95692/95692 [==============================] - 121s - loss: 0.1218 - acc: 0.9560 - val_loss: 0.1261 - val_acc: 0.9543\n",
      "Epoch 5/8\n",
      "95692/95692 [==============================] - 120s - loss: 0.1133 - acc: 0.9590 - val_loss: 0.1489 - val_acc: 0.9438\n",
      "Epoch 6/8\n",
      "95692/95692 [==============================] - 121s - loss: 0.1054 - acc: 0.9614 - val_loss: 0.1413 - val_acc: 0.9543\n",
      "Epoch 7/8\n",
      "95692/95692 [==============================] - 124s - loss: 0.0970 - acc: 0.9650 - val_loss: 0.1325 - val_acc: 0.9552\n",
      "Epoch 8/8\n",
      "95692/95692 [==============================] - 122s - loss: 0.0891 - acc: 0.9683 - val_loss: 0.1396 - val_acc: 0.9492\n",
      "<keras.callbacks.History object at 0x7fa9e37efd50>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "\n",
      "\n",
      " ======= training hack6_orig_v1 2017-10-04 17:51:12.440863\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/8\n",
      "95692/95692 [==============================] - 119s - loss: 0.2107 - acc: 0.9262 - val_loss: 0.1567 - val_acc: 0.9432\n",
      "Epoch 2/8\n",
      "95692/95692 [==============================] - 119s - loss: 0.1503 - acc: 0.9458 - val_loss: 0.1417 - val_acc: 0.9495\n",
      "Epoch 3/8\n",
      "95692/95692 [==============================] - 119s - loss: 0.1326 - acc: 0.9519 - val_loss: 0.1348 - val_acc: 0.9528\n",
      "Epoch 4/8\n",
      "95692/95692 [==============================] - 119s - loss: 0.1222 - acc: 0.9555 - val_loss: 0.1283 - val_acc: 0.9554\n",
      "Epoch 5/8\n",
      "95692/95692 [==============================] - 124s - loss: 0.1134 - acc: 0.9582 - val_loss: 0.1246 - val_acc: 0.9564\n",
      "Epoch 6/8\n",
      "95692/95692 [==============================] - 120s - loss: 0.1054 - acc: 0.9619 - val_loss: 0.1249 - val_acc: 0.9568\n",
      "Epoch 7/8\n",
      "95692/95692 [==============================] - 120s - loss: 0.0972 - acc: 0.9653 - val_loss: 0.1522 - val_acc: 0.9542\n",
      "Epoch 8/8\n",
      "95692/95692 [==============================] - 122s - loss: 0.0888 - acc: 0.9678 - val_loss: 0.1621 - val_acc: 0.9376\n",
      "<keras.callbacks.History object at 0x7fa9be747b90>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "\n",
      "\n",
      " ======= training hack6_orig_v2 2017-10-04 18:07:40.842215\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/8\n",
      "95692/95692 [==============================] - 121s - loss: 0.2198 - acc: 0.9231 - val_loss: 0.1599 - val_acc: 0.9411\n",
      "Epoch 2/8\n",
      "95692/95692 [==============================] - 122s - loss: 0.1543 - acc: 0.9432 - val_loss: 0.1386 - val_acc: 0.9484\n",
      "Epoch 3/8\n",
      "95692/95692 [==============================] - 118s - loss: 0.1346 - acc: 0.9509 - val_loss: 0.1462 - val_acc: 0.9463\n",
      "Epoch 4/8\n",
      "95692/95692 [==============================] - 118s - loss: 0.1231 - acc: 0.9551 - val_loss: 0.1277 - val_acc: 0.9535\n",
      "Epoch 5/8\n",
      "95692/95692 [==============================] - 120s - loss: 0.1146 - acc: 0.9586 - val_loss: 0.1269 - val_acc: 0.9550\n",
      "Epoch 6/8\n",
      "95692/95692 [==============================] - 117s - loss: 0.1062 - acc: 0.9620 - val_loss: 0.1298 - val_acc: 0.9557\n",
      "Epoch 7/8\n",
      "95692/95692 [==============================] - 121s - loss: 0.0984 - acc: 0.9649 - val_loss: 0.1507 - val_acc: 0.9412\n",
      "Epoch 8/8\n",
      "46592/95692 [=============>................] - ETA: 54s - loss: 0.0881 - acc: 0.9672"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-adc2f5ba5c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"\\nimport datetime\\n\\nprint('wiki:', wiki)\\n\\nhack6_wiki_models = []\\n\\nfor i in xrange(4):\\n    name = 'hack6_orig_v{}'.format(i)\\n    print('\\\\n\\\\n ======= training', name, datetime.datetime.now())\\n    model = ToxModel()\\n    model.train(wiki['train'], wiki['dev'], text_column='comment', label_column='is_toxic', model_name=name)\\n    hack6_wiki_models.append((name, model))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/src/model_tool.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data_path, validation_data_path, text_column, label_column, model_name)\u001b[0m\n\u001b[1;32m    138\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m           validation_data=(valid_data, valid_labels)))\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model trained!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/jetpack/src/bias_analysis_convai/virtualenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "\n",
    "print('wiki:', wiki)\n",
    "\n",
    "hack6_wiki_models = []\n",
    "\n",
    "for i in xrange(4):\n",
    "    name = 'hack6_orig_v{}'.format(i)\n",
    "    print('\\n\\n ======= training', name, datetime.datetime.now())\n",
    "    model = ToxModel()\n",
    "    model.train(wiki['train'], wiki['dev'], text_column='comment', label_column='is_toxic', model_name=name)\n",
    "    hack6_wiki_models.append((name, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hack7: even lower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki: {'test': '../data/wiki_test.csv', 'train': '../data/wiki_train.csv', 'dev': '../data/wiki_dev.csv'}\n",
      "\n",
      "\n",
      " ======= training hack7_orig_v0 2017-10-04 18:24:04.990942\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/8\n",
      "95692/95692 [==============================] - 119s - loss: 0.2284 - acc: 0.9207 - val_loss: 0.1788 - val_acc: 0.9353\n",
      "Epoch 2/8\n",
      "95692/95692 [==============================] - 120s - loss: 0.1618 - acc: 0.9409 - val_loss: 0.1500 - val_acc: 0.9455\n",
      "Epoch 3/8\n",
      "95692/95692 [==============================] - 119s - loss: 0.1448 - acc: 0.9471 - val_loss: 0.1396 - val_acc: 0.9487\n",
      "Epoch 4/8\n",
      "95692/95692 [==============================] - 120s - loss: 0.1351 - acc: 0.9510 - val_loss: 0.1371 - val_acc: 0.9487\n",
      "Epoch 5/8\n",
      "95692/95692 [==============================] - 117s - loss: 0.1267 - acc: 0.9532 - val_loss: 0.1323 - val_acc: 0.9521\n",
      "Epoch 6/8\n",
      "95692/95692 [==============================] - 118s - loss: 0.1203 - acc: 0.9556 - val_loss: 0.1306 - val_acc: 0.9530\n",
      "Epoch 7/8\n",
      "95692/95692 [==============================] - 119s - loss: 0.1144 - acc: 0.9578 - val_loss: 0.1381 - val_acc: 0.9532\n",
      "Epoch 8/8\n",
      "95692/95692 [==============================] - 117s - loss: 0.1092 - acc: 0.9597 - val_loss: 0.1305 - val_acc: 0.9539\n",
      "<keras.callbacks.History object at 0x7f08a0aaad10>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "\n",
      "\n",
      " ======= training hack7_orig_v1 2017-10-04 18:40:21.242152\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/8\n",
      "95692/95692 [==============================] - 121s - loss: 0.2463 - acc: 0.9142 - val_loss: 0.1779 - val_acc: 0.9355\n",
      "Epoch 2/8\n",
      "95692/95692 [==============================] - 122s - loss: 0.1711 - acc: 0.9385 - val_loss: 0.1540 - val_acc: 0.9435\n",
      "Epoch 3/8\n",
      "95692/95692 [==============================] - 124s - loss: 0.1519 - acc: 0.9447 - val_loss: 0.1446 - val_acc: 0.9469\n",
      "Epoch 4/8\n",
      "95692/95692 [==============================] - 122s - loss: 0.1404 - acc: 0.9488 - val_loss: 0.1371 - val_acc: 0.9497\n",
      "Epoch 5/8\n",
      "95692/95692 [==============================] - 122s - loss: 0.1317 - acc: 0.9519 - val_loss: 0.1394 - val_acc: 0.9477\n",
      "Epoch 6/8\n",
      "95692/95692 [==============================] - 123s - loss: 0.1245 - acc: 0.9541 - val_loss: 0.1356 - val_acc: 0.9497\n",
      "Epoch 7/8\n",
      "95692/95692 [==============================] - 121s - loss: 0.1185 - acc: 0.9568 - val_loss: 0.1282 - val_acc: 0.9532\n",
      "Epoch 8/8\n",
      "95692/95692 [==============================] - 121s - loss: 0.1135 - acc: 0.9586 - val_loss: 0.1279 - val_acc: 0.9541\n",
      "<keras.callbacks.History object at 0x7f087bc4bad0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "\n",
      "\n",
      " ======= training hack7_orig_v2 2017-10-04 18:57:06.006962\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/8\n",
      "95692/95692 [==============================] - 124s - loss: 0.2458 - acc: 0.9138 - val_loss: 0.1737 - val_acc: 0.9382\n",
      "Epoch 2/8\n",
      "95692/95692 [==============================] - 123s - loss: 0.1676 - acc: 0.9398 - val_loss: 0.1546 - val_acc: 0.9453\n",
      "Epoch 3/8\n",
      "95692/95692 [==============================] - 124s - loss: 0.1488 - acc: 0.9459 - val_loss: 0.1456 - val_acc: 0.9465\n",
      "Epoch 4/8\n",
      "95692/95692 [==============================] - 123s - loss: 0.1385 - acc: 0.9496 - val_loss: 0.1389 - val_acc: 0.9503\n",
      "Epoch 5/8\n",
      "95692/95692 [==============================] - 126s - loss: 0.1313 - acc: 0.9517 - val_loss: 0.1380 - val_acc: 0.9490\n",
      "Epoch 6/8\n",
      "95692/95692 [==============================] - 122s - loss: 0.1240 - acc: 0.9549 - val_loss: 0.1308 - val_acc: 0.9533\n",
      "Epoch 7/8\n",
      "95692/95692 [==============================] - 122s - loss: 0.1192 - acc: 0.9567 - val_loss: 0.1303 - val_acc: 0.9543\n",
      "Epoch 8/8\n",
      "95692/95692 [==============================] - 123s - loss: 0.1134 - acc: 0.9585 - val_loss: 0.1298 - val_acc: 0.9547\n",
      "<keras.callbacks.History object at 0x7f07d4dc4590>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "\n",
      "\n",
      " ======= training hack7_orig_v3 2017-10-04 19:14:02.523226\n",
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/8\n",
      "95692/95692 [==============================] - 122s - loss: 0.2524 - acc: 0.9120 - val_loss: 0.1832 - val_acc: 0.9355\n",
      "Epoch 2/8\n",
      "95692/95692 [==============================] - 122s - loss: 0.1730 - acc: 0.9379 - val_loss: 0.1576 - val_acc: 0.9429\n",
      "Epoch 3/8\n",
      "95692/95692 [==============================] - 121s - loss: 0.1524 - acc: 0.9439 - val_loss: 0.1534 - val_acc: 0.9460\n",
      "Epoch 4/8\n",
      "95692/95692 [==============================] - 121s - loss: 0.1397 - acc: 0.9491 - val_loss: 0.1413 - val_acc: 0.9485\n",
      "Epoch 5/8\n",
      "95692/95692 [==============================] - 121s - loss: 0.1316 - acc: 0.9518 - val_loss: 0.1548 - val_acc: 0.9495\n",
      "Epoch 6/8\n",
      "95692/95692 [==============================] - 119s - loss: 0.1240 - acc: 0.9550 - val_loss: 0.1419 - val_acc: 0.9518\n",
      "Epoch 7/8\n",
      "95692/95692 [==============================] - 121s - loss: 0.1180 - acc: 0.9568 - val_loss: 0.1300 - val_acc: 0.9533\n",
      "Epoch 8/8\n",
      "95692/95692 [==============================] - 122s - loss: 0.1118 - acc: 0.9588 - val_loss: 0.1347 - val_acc: 0.9540\n",
      "<keras.callbacks.History object at 0x7f07d1b84a10>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "CPU times: user 9h 34min 21s, sys: 53min 49s, total: 10h 28min 11s\n",
      "Wall time: 1h 6min 36s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "import datetime\n",
    "\n",
    "print('wiki:', wiki)\n",
    "\n",
    "hack7_wiki_models = []\n",
    "\n",
    "for i in xrange(4):\n",
    "    name = 'hack7_orig_v{}'.format(i)\n",
    "    print('\\n\\n ======= training', name, datetime.datetime.now())\n",
    "    model = ToxModel()\n",
    "    model.train(wiki['train'], wiki['dev'], text_column='comment', label_column='is_toxic', model_name=name)\n",
    "    hack7_wiki_models.append((name, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hack7_orig_v0', <model_tool.ToxModel instance at 0x7f08aae863f8>),\n",
       " ('hack7_orig_v1', <model_tool.ToxModel instance at 0x7f08a0a1eb90>),\n",
       " ('hack7_orig_v2', <model_tool.ToxModel instance at 0x7f087bc36bd8>),\n",
       " ('hack7_orig_v3', <model_tool.ToxModel instance at 0x7f07d4d9ebd8>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hack7_wiki_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring hack7_orig_v0 2017-10-04 19:40:38.211838\n",
      "scoring hack7_orig_v1 2017-10-04 19:40:57.152998\n",
      "scoring hack7_orig_v2 2017-10-04 19:41:15.393496\n",
      "scoring hack7_orig_v3 2017-10-04 19:41:33.708330\n",
      "CPU times: user 8min 33s, sys: 1min 8s, total: 9min 41s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wiki_test = pd.read_csv(wiki['test'])\n",
    "\n",
    "for (name, model) in hack7_wiki_models:\n",
    "    print('scoring', name, datetime.datetime.now())\n",
    "    wiki_test[name] = hack_score(model, wiki_test['comment'], maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>is_toxic</th>\n",
       "      <th>hack7_orig_v0</th>\n",
       "      <th>hack7_orig_v1</th>\n",
       "      <th>hack7_orig_v2</th>\n",
       "      <th>hack7_orig_v3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.039956</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.040605</td>\n",
       "      <td>0.061370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.004158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138074.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>`    I'm not sure if it's properly called ``fi...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007955</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.003587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200664.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thanks on the info on how to move a page....</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213105.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>`  : I should do that too, I agree, but I've a...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011738</td>\n",
       "      <td>0.012725</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>0.007882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>258303.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>`Well, I am not trying to pick a fight ) but I...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>372885.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>` :Thanks, but I don't have that link. I'm usi...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.001408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>427355.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>whats so pro-israeli propagandish about ara...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.041835</td>\n",
       "      <td>0.069951</td>\n",
       "      <td>0.186034</td>\n",
       "      <td>0.015614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>452612.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Oh, I'm sure I could find a copy around somewh...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.002031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>527004.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is something like Managing_Urban_America g...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.015585</td>\n",
       "      <td>0.103575</td>\n",
       "      <td>0.087239</td>\n",
       "      <td>0.021783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>576228.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>`Is the paragraph under ``He asserted the foll...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.003337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>587384.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>David, I have a couple of questions regardin...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.002731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>593987.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>There's nothing about Benito Mussolini or the ...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.013541</td>\n",
       "      <td>0.016068</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>597212.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>`  After the wasted bit on his sexuality, I ha...</td>\n",
       "      <td>2003</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.093408</td>\n",
       "      <td>0.145905</td>\n",
       "      <td>0.397114</td>\n",
       "      <td>0.021697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>598296.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this original work, or derived from another...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.000718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>630630.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>On second thought, why not instead provide a n...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>0.000835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>672149.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>`  It should be ``bail-out``, with a hyphen.  ...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>0.011186</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>672331.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The new paragraph is fine. Can I convince y...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.002462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>684743.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>:I don't think I understand you.  Would you ...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.002799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>712490.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Just one question though: How come when I lo...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.107742</td>\n",
       "      <td>0.016383</td>\n",
       "      <td>0.006370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>724915.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>`Where's the 24 defendants figure coming from?...</td>\n",
       "      <td>2003</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.029882</td>\n",
       "      <td>0.016309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>727773.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I understand...though 3 Feet High and Risin...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>0.013299</td>\n",
       "      <td>0.004917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>785036.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>` - ``Part of the US position...``....which pa...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.002222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>825305.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>oh the classic SM/DF response. That was only o...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.078916</td>\n",
       "      <td>0.045509</td>\n",
       "      <td>0.030018</td>\n",
       "      <td>0.021831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>890523.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Please notice that I am keepeng track and docu...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.005642</td>\n",
       "      <td>0.002464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>907842.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>:I believe it's because no other member of t...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.001571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>981476.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>How could you forget the Bowe-Holyfield tri...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018225</td>\n",
       "      <td>0.154210</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.014283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>997691.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>`  : I meant ``premature`` in the sense of ``b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.004096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1017722.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>:Hmmm... well I expected that it would proba...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1041178.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>` O, please excuse my misspelling of ``setted`...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.008926</td>\n",
       "      <td>0.166953</td>\n",
       "      <td>0.004140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31836</th>\n",
       "      <td>699334536.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>:::The current version is actually your versi...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.006123</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.001050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31837</th>\n",
       "      <td>699351159.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>` ::I'm afraid I have no interest whatsoever i...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.001337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31838</th>\n",
       "      <td>699355719.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>` :Thank you. Given the misuse of tools here a...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.046162</td>\n",
       "      <td>0.015451</td>\n",
       "      <td>0.034810</td>\n",
       "      <td>0.037610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31839</th>\n",
       "      <td>699358485.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>::Oh, are you one of this rogue admin's littl...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.014752</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>0.025547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31840</th>\n",
       "      <td>699360534.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>`  ::::No, ``Perfect`` got it wrong.  Four tim...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019229</td>\n",
       "      <td>0.006695</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.001914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31841</th>\n",
       "      <td>699363966.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>:D'aww! He matches this background colour I'm...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.001391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31842</th>\n",
       "      <td>699367482.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Additional: I don't agree with the assertion ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31843</th>\n",
       "      <td>699391644.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>`  == Cream? ==  Why is this called ``wolf cre...</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.187273</td>\n",
       "      <td>0.165655</td>\n",
       "      <td>0.183434</td>\n",
       "      <td>0.160988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31844</th>\n",
       "      <td>699392333.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>== Well? ==  What's wrong with you?</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.053243</td>\n",
       "      <td>0.155120</td>\n",
       "      <td>0.174729</td>\n",
       "      <td>0.050054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31845</th>\n",
       "      <td>699429881.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Here (Alessia Cara song)</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.007010</td>\n",
       "      <td>0.003833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31846</th>\n",
       "      <td>699430336.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>routine administration and helping out around ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.026793</td>\n",
       "      <td>0.019262</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.008893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31847</th>\n",
       "      <td>699456408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>:I agree. I think his name is Heinrich. Not H...</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.013193</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.002070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31848</th>\n",
       "      <td>699458324.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>You overtly undertake bold indignantly grote...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.135080</td>\n",
       "      <td>0.107660</td>\n",
       "      <td>0.071328</td>\n",
       "      <td>0.031144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31849</th>\n",
       "      <td>699474208.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>I'm sorry but I have to go now as I am consti...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.020922</td>\n",
       "      <td>0.016942</td>\n",
       "      <td>0.018366</td>\n",
       "      <td>0.016587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31850</th>\n",
       "      <td>699483392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>:To start: this cannot be discussed with you...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31851</th>\n",
       "      <td>699500374.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>::I never linked anything to Transformers! An...</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.005147</td>\n",
       "      <td>0.001978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31852</th>\n",
       "      <td>699563903.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>:: Oh, I thought you were an Indian Pariah D...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.024076</td>\n",
       "      <td>0.157799</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>0.055225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31853</th>\n",
       "      <td>699569747.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>` No, you utter RETARD! HISPANIC MEANS FROM SP...</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.512996</td>\n",
       "      <td>0.701793</td>\n",
       "      <td>0.483741</td>\n",
       "      <td>0.726391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31854</th>\n",
       "      <td>699589080.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>we would like to request you not to delete ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31855</th>\n",
       "      <td>699596750.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>::@ we have been over the prophethood bit lon...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31856</th>\n",
       "      <td>699619040.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>`  == Name ==  The article states:  ``Because ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31857</th>\n",
       "      <td>699621440.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>:True, put them in as well. I just torrented ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>0.031936</td>\n",
       "      <td>0.018342</td>\n",
       "      <td>0.013881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31858</th>\n",
       "      <td>699659494.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>im soory since when is google images not allow...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.551132</td>\n",
       "      <td>0.532469</td>\n",
       "      <td>0.729723</td>\n",
       "      <td>0.566166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31859</th>\n",
       "      <td>699667660.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This talk page is actually a better place to d...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31860</th>\n",
       "      <td>699683207.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>`  == Draft:The Beating Band ==  Hi again, I j...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31861</th>\n",
       "      <td>699688359.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>== These are the files on this topic that ha...</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.043491</td>\n",
       "      <td>0.059706</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>0.012746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31862</th>\n",
       "      <td>699698850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Yeah, I realized I created a duplicate ID. S...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.001259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31863</th>\n",
       "      <td>699820699.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>` Yes, from the word ``Guci`` or ``Puci`` mean...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.001516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31864</th>\n",
       "      <td>699851288.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The Institute for Historical Review is a pee...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31865</th>\n",
       "      <td>699897151.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Alternate option=== Is there perhaps enough ne...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.004330</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.005734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31866 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            rev_id  toxicity  \\\n",
       "0           8953.0  0.000000   \n",
       "1          28959.0  0.200000   \n",
       "2         138074.0  0.000000   \n",
       "3         200664.0  0.000000   \n",
       "4         213105.0  0.000000   \n",
       "5         258303.0  0.100000   \n",
       "6         372885.0  0.000000   \n",
       "7         427355.0  0.000000   \n",
       "8         452612.0  0.100000   \n",
       "9         527004.0  0.000000   \n",
       "10        576228.0  0.000000   \n",
       "11        587384.0  0.000000   \n",
       "12        593987.0  0.200000   \n",
       "13        597212.0  0.600000   \n",
       "14        598296.0  0.000000   \n",
       "15        630630.0  0.100000   \n",
       "16        672149.0  0.100000   \n",
       "17        672331.0  0.000000   \n",
       "18        684743.0  0.000000   \n",
       "19        712490.0  0.100000   \n",
       "20        724915.0  0.000000   \n",
       "21        727773.0  0.000000   \n",
       "22        785036.0  0.100000   \n",
       "23        825305.0  0.000000   \n",
       "24        890523.0  0.000000   \n",
       "25        907842.0  0.000000   \n",
       "26        981476.0  0.200000   \n",
       "27        997691.0  0.000000   \n",
       "28       1017722.0  0.000000   \n",
       "29       1041178.0  0.000000   \n",
       "...            ...       ...   \n",
       "31836  699334536.0  0.100000   \n",
       "31837  699351159.0  0.000000   \n",
       "31838  699355719.0  0.600000   \n",
       "31839  699358485.0  0.400000   \n",
       "31840  699360534.0  0.100000   \n",
       "31841  699363966.0  0.000000   \n",
       "31842  699367482.0  0.100000   \n",
       "31843  699391644.0  0.100000   \n",
       "31844  699392333.0  0.300000   \n",
       "31845  699429881.0  0.000000   \n",
       "31846  699430336.0  0.000000   \n",
       "31847  699456408.0  0.000000   \n",
       "31848  699458324.0  0.400000   \n",
       "31849  699474208.0  0.400000   \n",
       "31850  699483392.0  0.000000   \n",
       "31851  699500374.0  0.000000   \n",
       "31852  699563903.0  0.300000   \n",
       "31853  699569747.0  0.900000   \n",
       "31854  699589080.0  0.000000   \n",
       "31855  699596750.0  0.000000   \n",
       "31856  699619040.0  0.000000   \n",
       "31857  699621440.0  0.000000   \n",
       "31858  699659494.0  0.600000   \n",
       "31859  699667660.0  0.000000   \n",
       "31860  699683207.0  0.000000   \n",
       "31861  699688359.0  0.222222   \n",
       "31862  699698850.0  0.000000   \n",
       "31863  699820699.0  0.000000   \n",
       "31864  699851288.0  0.000000   \n",
       "31865  699897151.0  0.000000   \n",
       "\n",
       "                                                 comment  year  logged_in  \\\n",
       "0                              Elected or Electoral? JHK  2002      False   \n",
       "1      Please relate the ozone hole to increases in c...  2002       True   \n",
       "2      `    I'm not sure if it's properly called ``fi...  2002       True   \n",
       "3           Thanks on the info on how to move a page....  2002       True   \n",
       "4      `  : I should do that too, I agree, but I've a...  2002       True   \n",
       "5      `Well, I am not trying to pick a fight ) but I...  2002       True   \n",
       "6      ` :Thanks, but I don't have that link. I'm usi...  2002       True   \n",
       "7         whats so pro-israeli propagandish about ara...  2002       True   \n",
       "8      Oh, I'm sure I could find a copy around somewh...  2002       True   \n",
       "9          Is something like Managing_Urban_America g...  2002       True   \n",
       "10     `Is the paragraph under ``He asserted the foll...  2003       True   \n",
       "11       David, I have a couple of questions regardin...  2003       True   \n",
       "12     There's nothing about Benito Mussolini or the ...  2003       True   \n",
       "13     `  After the wasted bit on his sexuality, I ha...  2003      False   \n",
       "14     Is this original work, or derived from another...  2002       True   \n",
       "15     On second thought, why not instead provide a n...  2003       True   \n",
       "16     `  It should be ``bail-out``, with a hyphen.  ...  2003       True   \n",
       "17        The new paragraph is fine. Can I convince y...  2003       True   \n",
       "18       :I don't think I understand you.  Would you ...  2003       True   \n",
       "19       Just one question though: How come when I lo...  2003       True   \n",
       "20     `Where's the 24 defendants figure coming from?...  2003      False   \n",
       "21        I understand...though 3 Feet High and Risin...  2003       True   \n",
       "22     ` - ``Part of the US position...``....which pa...  2003       True   \n",
       "23     oh the classic SM/DF response. That was only o...  2003       True   \n",
       "24     Please notice that I am keepeng track and docu...  2003       True   \n",
       "25       :I believe it's because no other member of t...  2003       True   \n",
       "26        How could you forget the Bowe-Holyfield tri...  2003       True   \n",
       "27     `  : I meant ``premature`` in the sense of ``b...  2003       True   \n",
       "28       :Hmmm... well I expected that it would proba...  2003       True   \n",
       "29     ` O, please excuse my misspelling of ``setted`...  2003       True   \n",
       "...                                                  ...   ...        ...   \n",
       "31836   :::The current version is actually your versi...  2016       True   \n",
       "31837  ` ::I'm afraid I have no interest whatsoever i...  2016       True   \n",
       "31838  ` :Thank you. Given the misuse of tools here a...  2016       True   \n",
       "31839   ::Oh, are you one of this rogue admin's littl...  2016       True   \n",
       "31840  `  ::::No, ``Perfect`` got it wrong.  Four tim...  2016       True   \n",
       "31841   :D'aww! He matches this background colour I'm...  2016       True   \n",
       "31842   Additional: I don't agree with the assertion ...  2016       True   \n",
       "31843  `  == Cream? ==  Why is this called ``wolf cre...  2016      False   \n",
       "31844              == Well? ==  What's wrong with you?    2016      False   \n",
       "31845                           Here (Alessia Cara song)  2016       True   \n",
       "31846  routine administration and helping out around ...  2016       True   \n",
       "31847   :I agree. I think his name is Heinrich. Not H...  2016      False   \n",
       "31848    You overtly undertake bold indignantly grote...  2016       True   \n",
       "31849   I'm sorry but I have to go now as I am consti...  2016       True   \n",
       "31850    :To start: this cannot be discussed with you...  2016       True   \n",
       "31851   ::I never linked anything to Transformers! An...  2016      False   \n",
       "31852    :: Oh, I thought you were an Indian Pariah D...  2016       True   \n",
       "31853  ` No, you utter RETARD! HISPANIC MEANS FROM SP...  2016      False   \n",
       "31854     we would like to request you not to delete ...  2016       True   \n",
       "31855   ::@ we have been over the prophethood bit lon...  2016       True   \n",
       "31856  `  == Name ==  The article states:  ``Because ...  2016      False   \n",
       "31857   :True, put them in as well. I just torrented ...  2016       True   \n",
       "31858  im soory since when is google images not allow...  2016       True   \n",
       "31859  This talk page is actually a better place to d...  2016       True   \n",
       "31860  `  == Draft:The Beating Band ==  Hi again, I j...  2016       True   \n",
       "31861    == These are the files on this topic that ha...  2016      False   \n",
       "31862    Yeah, I realized I created a duplicate ID. S...  2016       True   \n",
       "31863  ` Yes, from the word ``Guci`` or ``Puci`` mean...  2016       True   \n",
       "31864    The Institute for Historical Review is a pee...  2016       True   \n",
       "31865  Alternate option=== Is there perhaps enough ne...  2016       True   \n",
       "\n",
       "            ns   sample split  is_toxic  hack7_orig_v0  hack7_orig_v1  \\\n",
       "0      article   random  test     False       0.039956       0.021583   \n",
       "1      article   random  test     False       0.005407       0.005966   \n",
       "2      article   random  test     False       0.007955       0.003299   \n",
       "3         user   random  test     False       0.000683       0.001605   \n",
       "4         user   random  test     False       0.011738       0.012725   \n",
       "5      article   random  test     False       0.002009       0.000854   \n",
       "6         user   random  test     False       0.001948       0.001588   \n",
       "7         user   random  test     False       0.041835       0.069951   \n",
       "8      article   random  test     False       0.003086       0.002681   \n",
       "9         user   random  test     False       0.015585       0.103575   \n",
       "10     article   random  test     False       0.001802       0.002285   \n",
       "11        user   random  test     False       0.000775       0.004933   \n",
       "12     article   random  test     False       0.006209       0.013541   \n",
       "13     article   random  test      True       0.093408       0.145905   \n",
       "14     article   random  test     False       0.002286       0.005080   \n",
       "15        user   random  test     False       0.000949       0.000927   \n",
       "16     article   random  test     False       0.001813       0.008641   \n",
       "17     article   random  test     False       0.000862       0.000522   \n",
       "18        user   random  test     False       0.001415       0.004725   \n",
       "19     article   random  test     False       0.004629       0.107742   \n",
       "20     article  blocked  test     False       0.002631       0.002603   \n",
       "21     article   random  test     False       0.011237       0.022876   \n",
       "22     article   random  test     False       0.001213       0.005360   \n",
       "23        user   random  test     False       0.078916       0.045509   \n",
       "24        user   random  test     False       0.001182       0.003095   \n",
       "25     article   random  test     False       0.000275       0.007940   \n",
       "26        user   random  test     False       0.018225       0.154210   \n",
       "27     article   random  test     False       0.001340       0.001802   \n",
       "28        user   random  test     False       0.001479       0.003128   \n",
       "29        user   random  test     False       0.011494       0.008926   \n",
       "...        ...      ...   ...       ...            ...            ...   \n",
       "31836     user  blocked  test     False       0.001686       0.006123   \n",
       "31837     user  blocked  test     False       0.014281       0.011637   \n",
       "31838     user  blocked  test      True       0.046162       0.015451   \n",
       "31839     user  blocked  test     False       0.014752       0.010101   \n",
       "31840     user  blocked  test     False       0.019229       0.006695   \n",
       "31841     user   random  test     False       0.000500       0.004496   \n",
       "31842     user  blocked  test     False       0.000541       0.000587   \n",
       "31843  article  blocked  test     False       0.187273       0.165655   \n",
       "31844     user  blocked  test     False       0.053243       0.155120   \n",
       "31845     user   random  test     False       0.004022       0.008497   \n",
       "31846     user   random  test     False       0.026793       0.019262   \n",
       "31847  article  blocked  test     False       0.001367       0.013193   \n",
       "31848  article  blocked  test     False       0.135080       0.107660   \n",
       "31849     user  blocked  test     False       0.020922       0.016942   \n",
       "31850  article   random  test     False       0.000231       0.001555   \n",
       "31851     user  blocked  test     False       0.002535       0.005388   \n",
       "31852     user  blocked  test     False       0.024076       0.157799   \n",
       "31853  article  blocked  test      True       0.512996       0.701793   \n",
       "31854     user   random  test     False       0.001161       0.001175   \n",
       "31855  article  blocked  test     False       0.000433       0.001620   \n",
       "31856  article  blocked  test     False       0.000458       0.000573   \n",
       "31857  article  blocked  test     False       0.014284       0.031936   \n",
       "31858     user  blocked  test      True       0.551132       0.532469   \n",
       "31859  article  blocked  test     False       0.000726       0.001501   \n",
       "31860     user   random  test     False       0.000297       0.000292   \n",
       "31861     user   random  test     False       0.043491       0.059706   \n",
       "31862     user  blocked  test     False       0.000376       0.002707   \n",
       "31863     user  blocked  test     False       0.001035       0.000469   \n",
       "31864  article  blocked  test     False       0.003151       0.002205   \n",
       "31865  article  blocked  test     False       0.001469       0.004330   \n",
       "\n",
       "       hack7_orig_v2  hack7_orig_v3  \n",
       "0           0.040605       0.061370  \n",
       "1           0.003303       0.004158  \n",
       "2           0.004808       0.003587  \n",
       "3           0.000855       0.000397  \n",
       "4           0.004290       0.007882  \n",
       "5           0.000479       0.000610  \n",
       "6           0.002655       0.001408  \n",
       "7           0.186034       0.015614  \n",
       "8           0.008497       0.002031  \n",
       "9           0.087239       0.021783  \n",
       "10          0.002342       0.003337  \n",
       "11          0.002548       0.002731  \n",
       "12          0.016068       0.001402  \n",
       "13          0.397114       0.021697  \n",
       "14          0.003726       0.000718  \n",
       "15          0.003089       0.000835  \n",
       "16          0.011186       0.003128  \n",
       "17          0.001596       0.002462  \n",
       "18          0.008165       0.002799  \n",
       "19          0.016383       0.006370  \n",
       "20          0.029882       0.016309  \n",
       "21          0.013299       0.004917  \n",
       "22          0.003009       0.002222  \n",
       "23          0.030018       0.021831  \n",
       "24          0.005642       0.002464  \n",
       "25          0.000907       0.001571  \n",
       "26          0.012927       0.014283  \n",
       "27          0.006300       0.004096  \n",
       "28          0.003867       0.002297  \n",
       "29          0.166953       0.004140  \n",
       "...              ...            ...  \n",
       "31836       0.003145       0.001050  \n",
       "31837       0.003784       0.001337  \n",
       "31838       0.034810       0.037610  \n",
       "31839       0.007130       0.025547  \n",
       "31840       0.008651       0.001914  \n",
       "31841       0.022217       0.001391  \n",
       "31842       0.000324       0.000520  \n",
       "31843       0.183434       0.160988  \n",
       "31844       0.174729       0.050054  \n",
       "31845       0.007010       0.003833  \n",
       "31846       0.026723       0.008893  \n",
       "31847       0.002589       0.002070  \n",
       "31848       0.071328       0.031144  \n",
       "31849       0.018366       0.016587  \n",
       "31850       0.000782       0.000790  \n",
       "31851       0.005147       0.001978  \n",
       "31852       0.013872       0.055225  \n",
       "31853       0.483741       0.726391  \n",
       "31854       0.000584       0.000266  \n",
       "31855       0.000683       0.000570  \n",
       "31856       0.000560       0.000319  \n",
       "31857       0.018342       0.013881  \n",
       "31858       0.729723       0.566166  \n",
       "31859       0.000783       0.000582  \n",
       "31860       0.000175       0.000089  \n",
       "31861       0.027539       0.012746  \n",
       "31862       0.000580       0.001259  \n",
       "31863       0.001846       0.001516  \n",
       "31864       0.001508       0.000567  \n",
       "31865       0.000818       0.005734  \n",
       "\n",
       "[31866 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxWSWxMVkluS/x2ZujUP+3GoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07b6ed8450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhhgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07b6f5f5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07b7166550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACPCAYAAABgS+5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07b6fcafd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opts = {'log': True, 'normed': False}\n",
    "\n",
    "for (name, _model) in hack7_wiki_models:\n",
    "    plt.figure(figsize=(3,2))\n",
    "    wiki_test[name].hist(**opts)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_toxic</th>\n",
       "      <th>hack7_orig_v0</th>\n",
       "      <th>hack7_orig_v1</th>\n",
       "      <th>hack7_orig_v2</th>\n",
       "      <th>hack7_orig_v3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21737</th>\n",
       "      <td>are you stupid or what????? read the very union text yourself!!!! it is clearly states that union is between TWO NATIONS!!!!!!!   h...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16427</th>\n",
       "      <td>== edits to Jimbo's user page ==  User:Jimbo Wales is not your sock puppet, and please do not go around like an April Fool. Thank...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13230</th>\n",
       "      <td>==are u stil a aids carrier?== hey amor, I was wondering if you still have HIV? welp, lemme know</td>\n",
       "      <td>True</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>btw mark arsten is a son of a bitch his cock is placed in a girls mouth  Hey guys I love chicken rice=)Hey guys I love chicken ric...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12629</th>\n",
       "      <td>== yo ==  can u stop being so fkn annoying my info on the a milli id right</td>\n",
       "      <td>True</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17413</th>\n",
       "      <td>BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>Check this out dumb Mexican: http://www.ripoffreport.com/reports/ripoff193659.htm</td>\n",
       "      <td>False</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>hello hw r u wot u been upto</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8603</th>\n",
       "      <td>==Louielim2007== I am suspecting louielim2007 as a sock puppet of jorbyma2007.  He is currenty vandalising the Yuri Gagarin page.</td>\n",
       "      <td>False</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23917</th>\n",
       "      <td>thanks for watching wiki raid threads and ruining fun, dick faggot thanks for watching wiki raid threads and ruining fun, dick fagg...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20487</th>\n",
       "      <td>It's my personal page, not your's. Not anybody's elses. It's not my fault it seems Wikipedia is ran by a bunch of idiots who can't...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13244</th>\n",
       "      <td>OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25855</th>\n",
       "      <td>== Worse than useless nitwit ==  Total waste of skin, this BS artist</td>\n",
       "      <td>True</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24740</th>\n",
       "      <td>== Reply ==  You take Wikipedia way too seriously.  Do something of your useless life, talk page stalker!</td>\n",
       "      <td>True</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28141</th>\n",
       "      <td>:::::::You know what you guys don't care about history., You wikipedia corrupted piles of shit can burn. I will contribute to bett...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18220</th>\n",
       "      <td>`this: ``Michael Wisner is an idiot.`` Or maybe I removed a useful ref in the process...ooops, again! I'll just go put that back in...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19129</th>\n",
       "      <td>==  I am going to bash your skull in and urinate all over your corpse. ==    I am going to bash your skull in and urinate all ove...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15432</th>\n",
       "      <td>Your space bar is broken? Or does it only refuse to work after full stops? Moron! LOL</td>\n",
       "      <td>False</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30358</th>\n",
       "      <td>http://theins.ru/news/4122 + http://russian.rt.com/article/77884 = fake (and shit) + official denial</td>\n",
       "      <td>True</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31373</th>\n",
       "      <td>WikiDan61 you dont have any brain your brain less person  u cant see notability and unknowningly delet page same done on SACHIn G...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12657</th>\n",
       "      <td>Yeah fine http://www.agilitynut.com/eateries/mcd.html  Eat it, nerdlinger.  This article is pure crap.</td>\n",
       "      <td>False</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12757</th>\n",
       "      <td>`  :Go on maps.google.com and type in ``pussy``, it will go to ``Pussy, France``   `</td>\n",
       "      <td>True</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18953</th>\n",
       "      <td>: By the way I wasn't joking when I welcomed Athenian very politely to the albanian page.Wikipedia sucks!</td>\n",
       "      <td>True</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19872</th>\n",
       "      <td>MCC or Metropolitan Community church is a church for all people who believe in our Lord Jesus Christ. A Gay Lesbian's Bisexuals, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25463</th>\n",
       "      <td>penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~p...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>YOU SMELL LIKE WIKI-CHEESE!!!!!~TEH LOLZ!category: wiki-cheese</td>\n",
       "      <td>True</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20266</th>\n",
       "      <td>::: Now you've done it.  They should have shown Leo taking a crap at the beginning of ever episode.  Brilliant!</td>\n",
       "      <td>False</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28002</th>\n",
       "      <td>` :: In other words: ``suggesting questions that might be addressed on a talk page is forbidden and is considered scandalous becaus...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29636</th>\n",
       "      <td>== edit warrer == why you go and try to recruit others to help you edit war? now you stalking people? man you need to step away ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>-kelly this is yo momma speaking, please stop being a nerd.-</td>\n",
       "      <td>True</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>`== File:Sadiq pavillion.jpg missing description details ==  Dear uploader: The media file you uploaded as File:Sadiq pavillion.jpg...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26752</th>\n",
       "      <td>`  == File:Hortonplains1.jpg missing description details ==  Dear uploader: The media file you uploaded as File:Hortonplains1.jpg i...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16456</th>\n",
       "      <td>== BD vs YOB and YOD categories ==  Please don't replace YOB/YOD categories wirth BD and/or Lifetime. There is no consensus for t...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29258</th>\n",
       "      <td>`  Dear Colleagues,  I thank the various administrators and editors for their patience, and for their comments here, on the various...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26887</th>\n",
       "      <td>== Beautiful Store sources ==  Hi, I have been doing some searching for English-language sources for your Beautiful Store article...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18539</th>\n",
       "      <td>== Speedy deletion of Template:Infobox college inline hockey team == A tag has been placed on Template:Infobox college inline ho...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11591</th>\n",
       "      <td>== Speedy deletion of Template:Music review header == A tag has been placed on Template:Music review header requesting that it be...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28595</th>\n",
       "      <td>== Infobox dates ==  Hi, when updating infobox stats you should update the  or  parameter by adding five tildes (~~~~~), which ge...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10281</th>\n",
       "      <td>:: came here from WP:3o.  I agree with 's comments, and do not see a blatant violation of the WP:SELFPUB policy, but given this a...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8516</th>\n",
       "      <td>Your a fat cunt == == Your a fucking fat ugly cunt == == Your a fat cunt == == Your a fucking fat ugly cunt == == Your a fat cunt ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>== Expanding Bay Area definition to match Census Bureau, including Santa Cruz and San Benito Counties ==  An update which was mad...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295</th>\n",
       "      <td>` :I find it hard to believe that you didn't know you write a verbatim copy of the website, but the content was   {{Unreferenced|da...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22562</th>\n",
       "      <td>`  == Edit request from ElSydd, 10 April 2011 ==    Please change Rio Ferdinand's height - which is incorrectly listed at 6'5``/195...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28589</th>\n",
       "      <td>== Arbcom Request ==  You are involved in a recently filed request for arbitration. Please review the request at Wikipedia:Arbitr...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26692</th>\n",
       "      <td>`  == Spain/Portugal ==  Hi.  Not sure if you have your centuries mixed up here: note that 1400s=15th century, 1500s=16th century, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30393</th>\n",
       "      <td>|url=http://www.espncricinfo.com/icc-cricket-world-cup-2015/content/story/853317.html|website=ESPNcricinfo|accessdate=21 March 2015...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19935</th>\n",
       "      <td>` == Talkback ==    |         == WikiProject Professional wrestling newsletter ==  {| class=``navbox collapsible collapsed`` style=...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>`   After reviewing the deletion, I think the error is technical.  I am on a Hughes Sat network that uses transparent proxies.  Thi...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13635</th>\n",
       "      <td>==Merge of County articles==  I will be proposing that all the County articles in England be merged into several articles, repres...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24518</th>\n",
       "      <td>`  == mgts ==  Next generation wireless networks are evolving into ``all-IP`` architectures, and SS7 over Internet Protocol (IP) is...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24632</th>\n",
       "      <td>`  ==Unsourced Awards==  First of all, thank you  and  for being fair and reasonable in regards to my edits to the Filmography sect...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31187</th>\n",
       "      <td>`  == Northern Cyprus IS a country == 1. Google Search: ````Northern Cyprus`` Country``: 856,000 results! 2. The definition of coun...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12286</th>\n",
       "      <td>`  == Hiroshima: August 6 and August 9, 1945 ==  I have once again removed the statement ``Operation suspended 6 August 1945 becaus...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25481</th>\n",
       "      <td>==Better source request for File:Full thickness rectal prolapse &amp; mucosal prolapse.jpg==  Thanks for uploading File:Full thicknes...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14850</th>\n",
       "      <td>`  ===History snapshots=== Here follow snapshots of the edit history related to merge of the articles Gaius Iulius Iullus and Gaius...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25182</th>\n",
       "      <td>== Wikipedia:Arbitration/Requests/Case/F opened == An arbitration case involving you has been opened, and is located at Wikipedi...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27108</th>\n",
       "      <td>The way I interpreted the wording was that they were specific, clarificatory applications of the primary criteria to the differen...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14287</th>\n",
       "      <td>`::Until and unless the MOS section is actually changed, the article follows current WP:MOS#Dates, particularly WP:MOS#Full date fo...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23799</th>\n",
       "      <td>`==Videography== ===Music videos===  Casting Director  ``Pon Tha Replay`` Rihanna (need date) Sean Paul- ``Now That I've Got Your ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20539</th>\n",
       "      <td>{Infobox bridge |bridge_name =  |native_name =  |native_name_lang =  |image =  |image_size =  |alt =  |caption =  |official_name = ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31866 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                      comment  \\\n",
       "21737  are you stupid or what????? read the very union text yourself!!!! it is clearly states that union is between TWO NATIONS!!!!!!!   h...   \n",
       "16427    == edits to Jimbo's user page ==  User:Jimbo Wales is not your sock puppet, and please do not go around like an April Fool. Thank...   \n",
       "13230                                     ==are u stil a aids carrier?== hey amor, I was wondering if you still have HIV? welp, lemme know      \n",
       "24349   btw mark arsten is a son of a bitch his cock is placed in a girls mouth  Hey guys I love chicken rice=)Hey guys I love chicken ric...   \n",
       "12629                                                              == yo ==  can u stop being so fkn annoying my info on the a milli id right   \n",
       "17413  BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALLS...   \n",
       "3412                                                       Check this out dumb Mexican: http://www.ripoffreport.com/reports/ripoff193659.htm    \n",
       "7192                                                                                                             hello hw r u wot u been upto   \n",
       "8603        ==Louielim2007== I am suspecting louielim2007 as a sock puppet of jorbyma2007.  He is currenty vandalising the Yuri Gagarin page.   \n",
       "23917  thanks for watching wiki raid threads and ruining fun, dick faggot thanks for watching wiki raid threads and ruining fun, dick fagg...   \n",
       "20487   It's my personal page, not your's. Not anybody's elses. It's not my fault it seems Wikipedia is ran by a bunch of idiots who can't...   \n",
       "13244  OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH NOES OH ...   \n",
       "25855                                                                  == Worse than useless nitwit ==  Total waste of skin, this BS artist     \n",
       "24740                            == Reply ==  You take Wikipedia way too seriously.  Do something of your useless life, talk page stalker!      \n",
       "28141   :::::::You know what you guys don't care about history., You wikipedia corrupted piles of shit can burn. I will contribute to bett...   \n",
       "18220  `this: ``Michael Wisner is an idiot.`` Or maybe I removed a useful ref in the process...ooops, again! I'll just go put that back in...   \n",
       "19129    ==  I am going to bash your skull in and urinate all over your corpse. ==    I am going to bash your skull in and urinate all ove...   \n",
       "15432                                                 Your space bar is broken? Or does it only refuse to work after full stops? Moron! LOL     \n",
       "30358                                    http://theins.ru/news/4122 + http://russian.rt.com/article/77884 = fake (and shit) + official denial   \n",
       "31373    WikiDan61 you dont have any brain your brain less person  u cant see notability and unknowningly delet page same done on SACHIn G...   \n",
       "12657                                  Yeah fine http://www.agilitynut.com/eateries/mcd.html  Eat it, nerdlinger.  This article is pure crap.   \n",
       "12757                                                    `  :Go on maps.google.com and type in ``pussy``, it will go to ``Pussy, France``   `   \n",
       "18953                              : By the way I wasn't joking when I welcomed Athenian very politely to the albanian page.Wikipedia sucks!    \n",
       "19872    MCC or Metropolitan Community church is a church for all people who believe in our Lord Jesus Christ. A Gay Lesbian's Bisexuals, ...   \n",
       "25463  penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~penis 8===D~~p...   \n",
       "984                                                                            YOU SMELL LIKE WIKI-CHEESE!!!!!~TEH LOLZ!category: wiki-cheese   \n",
       "20266                         ::: Now you've done it.  They should have shown Leo taking a crap at the beginning of ever episode.  Brilliant!   \n",
       "28002  ` :: In other words: ``suggesting questions that might be addressed on a talk page is forbidden and is considered scandalous becaus...   \n",
       "29636     == edit warrer == why you go and try to recruit others to help you edit war? now you stalking people? man you need to step away ...   \n",
       "743                                                                              -kelly this is yo momma speaking, please stop being a nerd.-   \n",
       "...                                                                                                                                       ...   \n",
       "20997  `== File:Sadiq pavillion.jpg missing description details ==  Dear uploader: The media file you uploaded as File:Sadiq pavillion.jpg...   \n",
       "26752  `  == File:Hortonplains1.jpg missing description details ==  Dear uploader: The media file you uploaded as File:Hortonplains1.jpg i...   \n",
       "16456    == BD vs YOB and YOD categories ==  Please don't replace YOB/YOD categories wirth BD and/or Lifetime. There is no consensus for t...   \n",
       "29258  `  Dear Colleagues,  I thank the various administrators and editors for their patience, and for their comments here, on the various...   \n",
       "26887    == Beautiful Store sources ==  Hi, I have been doing some searching for English-language sources for your Beautiful Store article...   \n",
       "18539     == Speedy deletion of Template:Infobox college inline hockey team == A tag has been placed on Template:Infobox college inline ho...   \n",
       "11591    == Speedy deletion of Template:Music review header == A tag has been placed on Template:Music review header requesting that it be...   \n",
       "28595    == Infobox dates ==  Hi, when updating infobox stats you should update the  or  parameter by adding five tildes (~~~~~), which ge...   \n",
       "10281    :: came here from WP:3o.  I agree with 's comments, and do not see a blatant violation of the WP:SELFPUB policy, but given this a...   \n",
       "8516    Your a fat cunt == == Your a fucking fat ugly cunt == == Your a fat cunt == == Your a fucking fat ugly cunt == == Your a fat cunt ...   \n",
       "13837    == Expanding Bay Area definition to match Census Bureau, including Santa Cruz and San Benito Counties ==  An update which was mad...   \n",
       "26295  ` :I find it hard to believe that you didn't know you write a verbatim copy of the website, but the content was   {{Unreferenced|da...   \n",
       "22562  `  == Edit request from ElSydd, 10 April 2011 ==    Please change Rio Ferdinand's height - which is incorrectly listed at 6'5``/195...   \n",
       "28589    == Arbcom Request ==  You are involved in a recently filed request for arbitration. Please review the request at Wikipedia:Arbitr...   \n",
       "26692  `  == Spain/Portugal ==  Hi.  Not sure if you have your centuries mixed up here: note that 1400s=15th century, 1500s=16th century, ...   \n",
       "30393  |url=http://www.espncricinfo.com/icc-cricket-world-cup-2015/content/story/853317.html|website=ESPNcricinfo|accessdate=21 March 2015...   \n",
       "19935  ` == Talkback ==    |         == WikiProject Professional wrestling newsletter ==  {| class=``navbox collapsible collapsed`` style=...   \n",
       "9549   `   After reviewing the deletion, I think the error is technical.  I am on a Hughes Sat network that uses transparent proxies.  Thi...   \n",
       "13635    ==Merge of County articles==  I will be proposing that all the County articles in England be merged into several articles, repres...   \n",
       "24518  `  == mgts ==  Next generation wireless networks are evolving into ``all-IP`` architectures, and SS7 over Internet Protocol (IP) is...   \n",
       "24632  `  ==Unsourced Awards==  First of all, thank you  and  for being fair and reasonable in regards to my edits to the Filmography sect...   \n",
       "31187  `  == Northern Cyprus IS a country == 1. Google Search: ````Northern Cyprus`` Country``: 856,000 results! 2. The definition of coun...   \n",
       "12286  `  == Hiroshima: August 6 and August 9, 1945 ==  I have once again removed the statement ``Operation suspended 6 August 1945 becaus...   \n",
       "25481    ==Better source request for File:Full thickness rectal prolapse & mucosal prolapse.jpg==  Thanks for uploading File:Full thicknes...   \n",
       "14850  `  ===History snapshots=== Here follow snapshots of the edit history related to merge of the articles Gaius Iulius Iullus and Gaius...   \n",
       "25182    == Wikipedia:Arbitration/Requests/Case/F opened == An arbitration case involving you has been opened, and is located at Wikipedi...   \n",
       "27108    The way I interpreted the wording was that they were specific, clarificatory applications of the primary criteria to the differen...   \n",
       "14287  `::Until and unless the MOS section is actually changed, the article follows current WP:MOS#Dates, particularly WP:MOS#Full date fo...   \n",
       "23799  `==Videography== ===Music videos===  Casting Director  ``Pon Tha Replay`` Rihanna (need date) Sean Paul- ``Now That I've Got Your ...   \n",
       "20539  {Infobox bridge |bridge_name =  |native_name =  |native_name_lang =  |image =  |image_size =  |alt =  |caption =  |official_name = ...   \n",
       "\n",
       "       is_toxic  hack7_orig_v0  hack7_orig_v1  hack7_orig_v2  hack7_orig_v3  \n",
       "21737      True          0.844          0.137          0.770          0.038  \n",
       "16427     False          0.876          0.047          0.084          0.025  \n",
       "13230      True          0.344          0.885          0.838          0.052  \n",
       "24349      True          0.643          0.935          0.008          0.729  \n",
       "12629      True          0.082          0.840          0.723          0.138  \n",
       "17413      True          0.912          0.185          0.443          0.022  \n",
       "3412      False          0.090          0.814          0.491          0.006  \n",
       "7192      False          0.007          0.657          0.069          0.703  \n",
       "8603      False          0.410          0.088          0.877          0.114  \n",
       "23917      True          0.960          0.926          0.538          0.186  \n",
       "20487      True          0.273          0.857          0.773          0.129  \n",
       "13244     False          0.808          0.008          0.290          0.642  \n",
       "25855      True          0.247          0.392          0.882          0.043  \n",
       "24740      True          0.600          0.826          0.819          0.070  \n",
       "28141      True          0.810          0.728          0.776          0.067  \n",
       "18220     False          0.678          0.712          0.935          0.109  \n",
       "19129     False          0.708          0.203          0.830          0.146  \n",
       "15432     False          0.119          0.749          0.825          0.845  \n",
       "30358      True          0.932          0.932          0.856          0.218  \n",
       "31373      True          0.081          0.538          0.074          0.767  \n",
       "12657     False          0.743          0.951          0.735          0.155  \n",
       "12757      True          0.715          0.885          0.682          0.107  \n",
       "18953      True          0.223          0.020          0.747          0.044  \n",
       "19872     False          0.359          0.781          0.103          0.042  \n",
       "25463      True          0.981          0.982          0.323          0.995  \n",
       "984        True          0.030          0.705          0.107          0.024  \n",
       "20266     False          0.189          0.831          0.273          0.107  \n",
       "28002      True          0.828          0.391          0.573          0.050  \n",
       "29636     False          0.054          0.779          0.403          0.137  \n",
       "743        True          0.060          0.779          0.533          0.190  \n",
       "...         ...            ...            ...            ...            ...  \n",
       "20997     False          0.000          0.000          0.000          0.000  \n",
       "26752     False          0.000          0.000          0.000          0.000  \n",
       "16456     False          0.000          0.000          0.000          0.000  \n",
       "29258     False          0.000          0.000          0.000          0.000  \n",
       "26887     False          0.000          0.000          0.000          0.000  \n",
       "18539     False          0.000          0.000          0.000          0.000  \n",
       "11591     False          0.000          0.000          0.000          0.000  \n",
       "28595     False          0.000          0.000          0.000          0.000  \n",
       "10281     False          0.000          0.000          0.000          0.000  \n",
       "8516       True          1.000          1.000          1.000          1.000  \n",
       "13837     False          0.000          0.000          0.000          0.000  \n",
       "26295     False          0.000          0.000          0.000          0.000  \n",
       "22562     False          0.000          0.000          0.000          0.000  \n",
       "28589     False          0.000          0.000          0.000          0.000  \n",
       "26692     False          0.000          0.000          0.000          0.000  \n",
       "30393     False          0.000          0.000          0.000          0.000  \n",
       "19935     False          0.000          0.000          0.000          0.000  \n",
       "9549      False          0.000          0.000          0.000          0.000  \n",
       "13635     False          0.000          0.000          0.000          0.000  \n",
       "24518     False          0.000          0.000          0.000          0.000  \n",
       "24632     False          0.000          0.000          0.000          0.000  \n",
       "31187     False          0.000          0.000          0.000          0.000  \n",
       "12286     False          0.000          0.000          0.000          0.000  \n",
       "25481     False          0.000          0.000          0.000          0.000  \n",
       "14850     False          0.000          0.000          0.000          0.000  \n",
       "25182     False          0.000          0.000          0.000          0.000  \n",
       "27108     False          0.000          0.000          0.000          0.000  \n",
       "14287     False          0.000          0.000          0.000          0.000  \n",
       "23799     False          0.000          0.000          0.000          0.000  \n",
       "20539     False          0.000          0.000          0.000          0.000  \n",
       "\n",
       "[31866 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_test['score_var'] = wiki_test[[name for (name,_model) in hack7_wiki_models]].var(axis=1)\n",
    "wiki_test.sort_values('score_var', ascending=False)[['comment', 'is_toxic'] + [name for (name,_model) in hack7_wiki_models]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f07b56956d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBpAg3AOBQGAACcI9EAgEBpD/HzDkEEqnSC1pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07b571d250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(wiki_test.hack7_orig_v0, wiki_test.hack7_orig_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/3\n",
      "95692/95692 [==============================] - 596s - loss: 0.1471 - acc: 0.9477 - val_loss: 0.1052 - val_acc: 0.9615\n",
      "Epoch 2/3\n",
      "95692/95692 [==============================] - 673s - loss: 0.1017 - acc: 0.9637 - val_loss: 0.0991 - val_acc: 0.9635\n",
      "Epoch 3/3\n",
      "95692/95692 [==============================] - 665s - loss: 0.0904 - acc: 0.9673 - val_loss: 0.1160 - val_acc: 0.9640\n",
      "<keras.callbacks.History object at 0x7fedf80cf3d0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "CPU times: user 4h 51min 12s, sys: 18min, total: 5h 9min 12s\n",
      "Wall time: 32min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MODEL_NAME = 'cnn_wiki_tox_v3'\n",
    "wiki_model = ToxModel()\n",
    "wiki_model.train(wiki['train'], wiki['dev'], text_column = 'comment', label_column = 'is_toxic', model_name = MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96897995365611589"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tool.compute_auc(wiki_test_set['is_toxic'], wiki_test_set['blahtest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wiki_model.prep_data_and_score(wiki['test'], text_column = 'comment', label_column = 'is_toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 689s - loss: 0.1433 - acc: 0.9489 - val_loss: 0.1220 - val_acc: 0.9584\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 698s - loss: 0.0991 - acc: 0.9641 - val_loss: 0.0988 - val_acc: 0.9650\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 698s - loss: 0.0880 - acc: 0.9678 - val_loss: 0.1419 - val_acc: 0.9504\n",
      "<keras.callbacks.History object at 0x7f8a55e9e6d0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n",
      "CPU times: user 4h 59min 1s, sys: 17min 33s, total: 5h 16min 34s\n",
      "Wall time: 35min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MODEL_NAME = 'cnn_debias_tox_v3'\n",
    "debias_model = ToxModel()\n",
    "debias_model.train(debias['train'], debias['dev'], text_column = 'comment', label_column = 'is_toxic', model_name = MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97595644478981225"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debias_model.prep_data_and_score(debias['test'], text_column = 'comment', label_column = 'is_toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 657s - loss: 0.1453 - acc: 0.9485 - val_loss: 0.1178 - val_acc: 0.9588\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 695s - loss: 0.0997 - acc: 0.9646 - val_loss: 0.1042 - val_acc: 0.9655\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 695s - loss: 0.0898 - acc: 0.9680 - val_loss: 0.0953 - val_acc: 0.9657\n",
      "<keras.callbacks.History object at 0x7fb500320790>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "#TODOOOOOOOOOOOOOOOOOOOOOO\n",
    "MODEL_NAME = 'cnn_debias_random_tox_v3'\n",
    "debias_random_model = ToxModel()\n",
    "debias_random_model.train(random['train'], random['dev'], text_column = 'comment', label_column = 'is_toxic', model_name = MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97641284855407495"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debias_random_model.prep_data_and_score(random['test'], text_column = 'comment', label_column = 'is_toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
