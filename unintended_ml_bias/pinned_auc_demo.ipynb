{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMykUGMauh9b"
   },
   "source": [
    "# Conversation AI's Pinned AUC Unintended Model Bias Demo\n",
    "\n",
    "Author: ldixon@google.com, jetpack@google.com, sorenj@google.com, nthain@google.com, lucyvasserman@google.com\n",
    "\n",
    "***\n",
    "Click [here](https://colab.research.google.com/github/conversationai/unintended-ml-bias-analysis/blob/master/unintended_ml_bias/pinned_auc_demo.ipynb) to run this colab interactively at on colab.research.google.com.\n",
    "\n",
    "***\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrates Pinned AUC as an unintended model bias metric for Conversation AI wikipedia models.\n",
    "\n",
    "See the paper [Measuring and Mitigating Unintended Bias in Text Classification](https://github.com/conversationai/unintended-ml-bias-analysis/blob/master/presentations/measuring-mitigating-unintended-bias-paper.pdf)\n",
    "for background, detailed explanation, and experimental results.\n",
    "\n",
    "Also see  https://developers.google.com/machine-learning/fairness-overview for more info on Google's\n",
    "Machine Learning Fairness work.\n",
    "\n",
    "__Disclaimer__\n",
    "*   This notebook contains experimental code, which may be changed without notice.\n",
    "*   The ideas here are some ideas relevant to fairness - they are not the whole story!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jp8VFI-FZ8Dl"
   },
   "source": [
    "We start by loading some libraries that we will use and customizing the visualization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dBRNXZ06Y5Hw"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q git+https://github.com/conversationai/unintended-ml-bias-analysis\n",
    "!pip install -U -q pandas==0.22.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0VlJ-_r9VjiV"
   },
   "outputs": [],
   "source": [
    "from unintended_ml_bias import model_bias_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "j7-dSMztPn3y"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "GcwTqGF6z0Cv"
   },
   "outputs": [],
   "source": [
    "cm = sns.light_palette(\"red\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0W5oN9XD7uG"
   },
   "source": [
    "## Model Families - capture training variance\n",
    "\"Model Families\" allows the results to capture training variance by grouping different\n",
    "training versions of each model together. model_families is a list of lists, each \n",
    "sub-list (\"model_family\") contains the names of different training versions of the same model. \n",
    "\n",
    "We compare 3 versions each of three different models, **\"wiki_cnn\"**, **\"wiki_debias_random\"**,\n",
    "and **\"wiki_debias\"**.\n",
    "\n",
    "*   **\"wiki_cnn\"** is a CNN trained on the original, unmodified training data.\n",
    "*   **\"wiki_debias\"** is the same model as wiki_cnn, but trained on a modified dataset that has undergone bias mitigation: we added presumed-non-toxic data from Wikipedia articles, specifically sampled to address the bias found in the original dataset.\n",
    "*   **\"wiki_debias_random\"** is the same model, trained on a modified dataset that has had random Wikipedia article data added to it (not specific to the bias we found). This serves as a control for the debiasing treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UoO-czF-UsND"
   },
   "outputs": [],
   "source": [
    "model_families = [\n",
    "    ['cnn_attention_debias_tox_v2_100', 'cnn_attention_debias_tox_v2_101','cnn_attention_debias_tox_v2_102'],\n",
    "    ['wiki_cnn_v3_100', 'wiki_cnn_v3_101', 'wiki_cnn_v3_102'],\n",
    "    ['wiki_debias_cnn_v3_100', 'wiki_debias_cnn_v3_101', 'wiki_debias_cnn_v3_102'],\n",
    "    ['wiki_debias_random_cnn_v3_100', 'wiki_debias_random_cnn_v3_101', 'wiki_debias_random_cnn_v3_102'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RdRqdLOU9jmq",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias_madlibs_77k.csv           bias_madlibs_89k_scored.csv\r\n",
      "bias_madlibs_77k_scored_2.csv  toxicity_fuzzed_testset.csv\r\n",
      "bias_madlibs_77k_scored.csv    toxicity_nonfuzzed_testset.csv\r\n",
      "bias_madlibs_89k.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Read the scored data into DataFrame\n",
    "%ls eval_datasets\n",
    "df = pd.read_csv(\"eval_datasets/bias_madlibs_77k_scored_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iFpji3EXPsdq"
   },
   "outputs": [],
   "source": [
    "# Add columns for each subgroup.\n",
    "terms = [line.strip() for line in pkg_resources.resource_stream(\"unintended_ml_bias\", \"bias_madlibs_data/adjectives_people.txt\")]\n",
    "model_bias_analysis.add_subgroup_columns_from_text(df, 'text', terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D3ZJSKY8FHFH"
   },
   "source": [
    "## Data Format\n",
    "At this point, our scored data is in DataFrame df, with columns:\n",
    "\n",
    "*   text: Full text of the comment.\n",
    "*   label: True if the comment is Toxic, False otherwise.\n",
    "*   < model name >: One column per model, cells contain the score from that model.\n",
    "*   < subgroup >: One column per identity, True if the comment mentions this identity.\n",
    "\n",
    "You can run the analysis below on any data in this format. Subgroup labels can be \n",
    "generated via words in the text as done above, or come from human labels if you have them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vTrKsfIcxoBh"
   },
   "source": [
    "# Unintended Bias Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPXk78apx2-Z"
   },
   "source": [
    "## Pinned AUC\n",
    "Pinned AUC measures the extent of unintended bias of a real-value score function\n",
    "by measuring each sub-group's divergence from the general distribution.\n",
    "\n",
    "Let $D$ represent the full data set and $D_g$ be the set of examples in subgroup\n",
    "$g$. Then:\n",
    "\n",
    "\n",
    "$$ Pinned \\ dataset \\ for \\ group \\ g = pD_g = s(D_g) + s(D), |s(D_g)| = |s(D)| $$\n",
    "\n",
    "$$ Pinned \\ AUC \\ for \\ group \\ g = pAUC_g = AUC(pD_g) $$\n",
    "\n",
    "$$ Pinned \\ AUC \\ Squared \\ Equality \\ Difference = \\Sigma_{g \\in G}(AUC - pAUC_g)^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65U3PzABPiE6"
   },
   "source": [
    "## Pinned AUC Equality Difference\n",
    "The table below shows the pinned AUC equality difference for each model family.\n",
    "Lower scores (lighter red) represent more similarity between each group's pinned AUC, which means\n",
    "less unintended bias.\n",
    "\n",
    "On this set, the wiki_debias_cnn model demonstrates least unintended bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1951,
     "status": "ok",
     "timestamp": 1516308582789,
     "user": {
      "displayName": "Lucy Vasserman",
      "photoUrl": "//lh5.googleusercontent.com/-vI1xTLKix-Q/AAAAAAAAAAI/AAAAAAAAHco/7H58dlLeJ24/s50-c-k-no/photo.jpg",
      "userId": "111930900983976316726"
     },
     "user_tz": 300
    },
    "id": "W8p5iHW2RZmN",
    "outputId": "df15b4c5-fef0-47e1-860b-800fcdf453db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row0_col1 {\n",
       "            background-color:  #ffe5e5;\n",
       "        }    #T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row1_col1 {\n",
       "            background-color:  #ff0000;\n",
       "        }    #T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row2_col1 {\n",
       "            background-color:  #ffd5d5;\n",
       "        }    #T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row3_col1 {\n",
       "            background-color:  #ff6060;\n",
       "        }</style>  \n",
       "<table id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >model_family</th> \n",
       "        <th class=\"col_heading level0 col1\" >pinned_auc_equality_difference</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74level0_row0\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row0_col0\" class=\"data row0 col0\" >cnn_attention_debias_tox_v2_10</td> \n",
       "        <td id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row0_col1\" class=\"data row0 col1\" >0.0127239</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74level0_row1\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row1_col0\" class=\"data row1 col0\" >wiki_cnn_v3_10</td> \n",
       "        <td id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row1_col1\" class=\"data row1 col1\" >0.0436979</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74level0_row2\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row2_col0\" class=\"data row2 col0\" >wiki_debias_cnn_v3_10</td> \n",
       "        <td id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row2_col1\" class=\"data row2 col1\" >0.0149677</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74level0_row3\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row3_col0\" class=\"data row3 col0\" >wiki_debias_random_cnn_v3_10</td> \n",
       "        <td id=\"T_5e393e4c_20c9_11e8_a09d_7cdd90a5bf74row3_col1\" class=\"data row3 col1\" >0.0307355</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f64986389d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_diff = model_bias_analysis.per_subgroup_auc_diff_from_overall(df, terms, model_families, squared_error=True)\n",
    "# sort to guarantee deterministic output\n",
    "eq_diff.sort_values(by=['model_family'], inplace=True)\n",
    "eq_diff.reset_index(drop=True, inplace=True)\n",
    "eq_diff.style.background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bEC5cAsyC05"
   },
   "source": [
    "## Pinned AUC Graphs\n",
    "The graphs below show per-group Pinned AUC for each subgroup and each model. Each\n",
    "identity group shows 3 points, each representing the pinned AUC for one training \n",
    "version of the model. More consistency among the values represents less unintended bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1061,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 3
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4630,
     "status": "ok",
     "timestamp": 1516308587443,
     "user": {
      "displayName": "Lucy Vasserman",
      "photoUrl": "//lh5.googleusercontent.com/-vI1xTLKix-Q/AAAAAAAAAAI/AAAAAAAAHco/7H58dlLeJ24/s50-c-k-no/photo.jpg",
      "userId": "111930900983976316726"
     },
     "user_tz": 300
    },
    "id": "QqMmPTreOCPf",
    "outputId": "7287582d-c468-40dd-81ee-61db5911a0c5"
   },
   "outputs": [],
   "source": [
    "pinned_auc_results = model_bias_analysis.per_subgroup_aucs(df, terms, model_families, 'label')\n",
    "for family in model_families:\n",
    "  name = model_bias_analysis.model_family_name(family)\n",
    "  model_bias_analysis.per_subgroup_scatterplots(\n",
    "      pinned_auc_results,\n",
    "      'subgroup',\n",
    "      name + '_aucs',\n",
    "      name + ' Pinned AUC',\n",
    "      y_lim=(0.8, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "pinned_auc_demo.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/conversationai/unintended-ml-bias-analysis/blob/master/unintended_ml_bias/pinned_auc_demo.ipynb",
     "timestamp": 1516308177132
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
